{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PfIOaPVFMKBD-OHXUqkolkflROuUgRtd",
      "authorship_tag": "ABX9TyNoZR/cLHY9KSI5v+UMJLpn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Justin-Jonany/FLARE_Implementation/blob/main/notebooks_and_demonstration/1_FLARE_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FLARE**\n",
        "We know that when LLM's output tokens, they also output the probabilities associated with each token, as a result of the transformer model's outputting layer. However, what does these number mean? There have been several researchs arround this, some takes these numbers as how confident the LLMs are with its answer. This means that what if for every token that an LLM outputs with low probability, we assist the LLM to make it sure.\n",
        "\n",
        "Introducing, the paper \"[Active Retrieval Augmented Generation](https://arxiv.org/pdf/2305.06983)\" by Jiang ZB and fellow researchers written on October 22, 2023, and the goal of this project will be to implement the paper and test it for various tasks. Although, at the the time of this project's starting date (August 6, 2024), it may seem relatively out-of-date, this technique is still relevant and efficient, and can be implemented for any future model that allows users to access the probabilities of each tokens.\n",
        "\n",
        "All functions can be accessed in my github repository: [github.com/Justin-Jonany/FLARE_Implementation](https://github.com/Justin-Jonany/FLARE_Implementation)\n",
        "\n",
        "## **Summary of the Paper (outputted by my implementation of FLARE)**\n",
        "The paper explores the limitations of existing retrieval-augmented language models, which typically execute a single retrieval based solely on user input, leading to inaccurate and contextually irrelevant outputs. Recognizing the need for continual information gathering to enhance long-form text generation, the authors propose Forward-Looking Active Retrieval Augmented Generation (FLARE).\n",
        "\n",
        "This method employs an iterative approach, where the model generates a provisional next sentence to identify low-confidence tokens and selectively retrieves relevant information to refine its output. FLARE operates through two main strategies: FLAREinstruct, which prompts the model to create retrieval queries as needed, and FLAREdirect, where the model’s generative output directly informs search queries. The authors empirically validate FLARE across multiple knowledge-intensive tasks and demonstrate its superior performance compared to traditional retrieval methods, emphasizing its effectiveness in enriching the generation process with accurate, contextually rich information that adapts to the evolving needs of text generation.\n",
        "\n",
        "## **My Implementation**\n",
        "I'm going to implement the FLARE Instruct version of the paper based on the paper's algorithm structure and will not be based-on the paper's source code. I will additionally use GPT-4o instead of GPT 3.5. The retriever can be any object that has a method called \"get_relevant_documents\". For this notebook, the retriever is Chroma with a langchain OpenAI Embedding.\n",
        "\n",
        "The steps of the RAG are the following:\n",
        "### 1. Use the LLM for traditional RAG or regular querying to answer the question\n",
        "As the first output of the recursive steps, the question will be invoked on the LLM given a context retrieved from a basic RAG call to the retriever.\n",
        "\n",
        "### 2. Check logits for each token from the LLM and annotate with a symbol any where the llm is not confident.\n",
        "The next step is to check each token's logarithmic probabilities, and for a given tolerance, a function will automatically  modify the OpenAI Response object's logprob field with annotations. For every phrase where the it's unsure, it will be marked as the following: \"[uncertain]...[/uncertain]\". This is done with the assumption, that if the LLM outputs token with low probabilities, it implies that it's unsure about it, meaning it has a higher chance to be wrong.\n",
        "\n",
        "### 3. Constructing questions to get a more confident answer for that token.\n",
        "Now for all phrases that's marked as uncertain, the LLM will be reinvoked to turn the \"[uncertain]...[/uncertain]\" into \"[search(question)]\", where \"question\" would be the prompt to answer the uncertain phrase. After, these questions will be extracted into a dictionary, to ease the question-answering process.\n",
        "\n",
        "### 4. Answer these questions\n",
        "Now, having the questions, the LLM will be used to answer each question with a prompt of the following format: a shortened version of the steps so far, the annotated answer, the question, and finally the context retrieved. All answers will be saved a in dictionary as the value, and the question as the key.\n",
        "\n",
        "### 5. Reconstruct the answer\n",
        "Now having, all the answers, the LLM will be used the reconstruct the final answer.\n",
        "\n",
        "## **Example Steps**\n",
        "For the question: Why did Arkad believe that good luck follows opportunity?. My implementaton of FLARE would look like this:\n",
        "\n",
        "### Step 1. Regular RAG Answer\n",
        "In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them.\n",
        "\n",
        "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success.\n",
        "\n",
        "### Step 2. Annotating uncertain tokens\n",
        "In \"The Richest Man in ([uncertain] Babylon,\" Arkad, who is the [/uncertain])  richest man in Babylon, believes that good luck follows opportunity because he sees luck as ([uncertain] a byproduct of one’s readiness [/uncertain])  to seize opportunities when they arise. ([uncertain] He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the [/uncertain])  opportunities presented to them.\n",
        "\n",
        " ([uncertain]Arkad suggests that those who are diligent, prepared, and willing to work toward their goals [/uncertain])  are more likely to encounter ([uncertain] opportunities that lead to success. [/uncertain])  ([uncertain] In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take [/uncertain])  risks, and the ability to ([uncertain] recognize and act on chances [/uncertain])  ([uncertain] that life presents. [/uncertain])  ([uncertain] This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial [/uncertain])  success.\n",
        "\n",
        " ### Step 3. Constructing questions to fix the low-confidence tokens\n",
        " In \"The Richest Man in [Search(What is the setting of the book \"The Richest Man in Babylon\"?)], Arkad, who is the [Search(Who is Arkad in the context of the book?)] richest man in Babylon, believes that good luck follows opportunity because he sees luck as [Search(What does Arkad mean by \"a byproduct of one’s readiness\" in terms of seizing opportunities?)] to seize opportunities when they arise. [Search(Why do people miss chances to become wealthy according to Arkad?)] He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the [Search(What type of opportunities does Arkad refer to in the book?)] opportunities presented to them.\n",
        "\n",
        "[Search(What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?)] Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter [Search(What are examples of opportunities that lead to success in the book?)] opportunities that lead to success. [Search(What does Arkad say about the nature of luck?)] In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take [Search(What type of risks does Arkad encourage people to take?)] risks, and the ability to [Search(How does one recognize and act on chances?)][Search(What does Arkad mean by \"chances\" in the context of life?)] recognize and act on chances [Search(What does Arkad mean by \"that life presents\"?)] that life presents. [Search(Why does Arkad advocate for a proactive approach to achieving financial success?)] This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial [Search(What does financial success mean in the context of the book?)] success.\n",
        "\n",
        "### Step 4. Extract as dictionary\n",
        "{'1': \"What is the setting of the book 'The Richest Man in Babylon'?\",\n",
        " '2': 'Who is Arkad in the context of the book?',\n",
        " '3': \"What does Arkad mean by 'a byproduct of one’s readiness' in terms of seizing opportunities?\",\n",
        " '4': 'Why do people miss chances to become wealthy according to Arkad?',\n",
        " '5': 'What type of opportunities does Arkad refer to in the book?',\n",
        " '6': 'What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?',\n",
        " '7': 'What are examples of opportunities that lead to success in the book?',\n",
        " '8': 'What does Arkad say about the nature of luck?',\n",
        " '9': 'What type of risks does Arkad encourage people to take?',\n",
        " '10': 'How does one recognize and act on chances?',\n",
        " '11': \"What does Arkad mean by 'chances' in the context of life?\",\n",
        " '12': \"What does Arkad mean by 'that life presents'?\",\n",
        " '13': 'Why does Arkad advocate for a proactive approach to achieving financial success?',\n",
        " '14': 'What does financial success mean in the context of the book?'}\n",
        "\n",
        " ### Step 5. Answering each question\n",
        " 1. **Question**: What is the setting of the book 'The Richest Man in Babylon'?\\\n",
        "**Answer**: Arkad believed that good luck follows opportunity because he understood that wealth is not simply a matter of fate or luck; it is a result of taking action when opportunities present themselves. During his journey to accumulate wealth, he realized that many people fail to recognize the opportunities available to them or choose not to act on them. Instead of waiting for fortune to smile upon them, Arkad emphasized the importance of being proactive, diligent, and prepared to seize chances when they arise.\\\n",
        "According to Arkad, those who actively seek opportunities, educate themselves about how to manage and grow their wealth, and are willing to work and invest wisely are more likely to create their own \"luck.\" This philosophy is encapsulated in his advice that a part of all one earns should be kept for oneself, which reflects the notion that individuals have the power to influence their financial destiny by being open to opportunity and ready to take positive steps toward wealth accumulation.\n",
        "\n",
        "2. Question: Who is Arkad in the context of the book?\\\n",
        "Answer: Arkad believed that good luck follows opportunity because he understood that those who are prepared and willing to act upon the opportunities that life presents are more likely to find success. Essentially, luck, in Arkad's view, is not a mere coincidence; instead, it is a result of one’s readiness to seize chances and make the most of them. He recognized that many people fail to achieve wealth because they do not identify or take action on the opportunities available to them.\\\n",
        "Moreover, Arkad’s own experiences shaped this philosophy. He started his own fortune in humble beginnings and learned valuable lessons that he later shared with others in Babylon. His teachings emphasized that by being proactive, recognizing potential opportunities, and being willing to take calculated risks, individuals could attract what they perceive as \"good luck.\" Thus, in Arkad's perspective, the consistent effort towards preparation and action creates the conditions for good luck to manifest.\n",
        "\n",
        "...other question-answer pairs...\n",
        "\n",
        "### Step 6. Reconstructing the final answer:\n",
        "In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he understands that wealth is not simply a matter of fate or luck; it is a result of taking action when opportunities present themselves. Throughout his life, he observed that many people fail to recognize the opportunities available to them or choose not to act on them. Instead of waiting for fortune to smile upon them, Arkad emphasized the importance of being proactive, diligent, and prepared to seize chances when they arise.\n",
        "\n",
        "According to Arkad, those who actively seek opportunities, educate themselves about how to manage and grow their wealth, and are willing to work and invest wisely are more likely to create their own \"luck.\" He noted that while opportunities are available to everyone, only a few grasp them and achieve their desires, while the majority hesitate or falter and consequently fall behind. This perspective underscores that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on possibilities that life presents.\n",
        "\n",
        "In essence, Arkad's philosophy encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. He conveys that good luck is closely linked to the willingness to engage with life's opportunities, reinforcing the idea that preparation and action can transform luck from a mere chance event into a consistent part of one's journey towards success.\n",
        "\n",
        "\n",
        "\n",
        "## **FLARE Use-Cases**\n",
        "In the following notebooks, FLARE will be used for various tasks: Fund Statement PDF Extraction, Novel Question-Answering, and Scientific Journal Summarization."
      ],
      "metadata": {
        "id": "E--Sh-3cJQD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "pTscgN3x1U25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Justin-Jonany/FLARE_Implementation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxIDbzBFgopa",
        "outputId": "41003191-c5de-47a6-9473-0efacc2b4ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FLARE_Implementation'...\n",
            "remote: Enumerating objects: 242, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 242 (delta 126), reused 177 (delta 72), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (242/242), 6.92 MiB | 13.96 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r FLARE_Implementation/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_z9NqY0gqzK",
        "outputId": "edab8eb8-526f-493f-9c04-2a17ae055735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai (from -r FLARE_Implementation/requirements.txt (line 1))\n",
            "  Downloading openai-1.46.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r FLARE_Implementation/requirements.txt (line 2)) (1.26.4)\n",
            "Collecting pytesseract (from -r FLARE_Implementation/requirements.txt (line 3))\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langchain_core (from -r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading langchain_core-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdf2image (from -r FLARE_Implementation/requirements.txt (line 5))\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting easyocr (from -r FLARE_Implementation/requirements.txt (line 6))\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pymupdf (from -r FLARE_Implementation/requirements.txt (line 7))\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai->-r FLARE_Implementation/requirements.txt (line 1))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai->-r FLARE_Implementation/requirements.txt (line 1))\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->-r FLARE_Implementation/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract->-r FLARE_Implementation/requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract->-r FLARE_Implementation/requirements.txt (line 3)) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_core->-r FLARE_Implementation/requirements.txt (line 4)) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain_core->-r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.117 (from langchain_core->-r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading langsmith-0.1.123-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_core->-r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (0.23.2)\n",
            "Collecting python-bidi (from easyocr->-r FLARE_Implementation/requirements.txt (line 6))\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2.0.6)\n",
            "Collecting pyclipper (from easyocr->-r FLARE_Implementation/requirements.txt (line 6))\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr->-r FLARE_Implementation/requirements.txt (line 6))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting PyMuPDFb==1.24.10 (from pymupdf->-r FLARE_Implementation/requirements.txt (line 7))\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r FLARE_Implementation/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r FLARE_Implementation/requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r FLARE_Implementation/requirements.txt (line 1)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r FLARE_Implementation/requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r FLARE_Implementation/requirements.txt (line 1))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain_core->-r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.117->langchain_core->-r FLARE_Implementation/requirements.txt (line 4))\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain_core->-r FLARE_Implementation/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r FLARE_Implementation/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r FLARE_Implementation/requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain_core->-r FLARE_Implementation/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain_core->-r FLARE_Implementation/requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr->-r FLARE_Implementation/requirements.txt (line 6)) (1.3.0)\n",
            "Downloading openai-1.46.1-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.1/375.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_core-0.3.1-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.123-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, tenacity, pytesseract, PyMuPDFb, pdf2image, orjson, jsonpointer, jiter, h11, pymupdf, jsonpatch, httpcore, httpx, openai, langsmith, easyocr, langchain_core\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed PyMuPDFb-1.24.10 easyocr-1.7.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain_core-0.3.1 langsmith-0.1.123 ninja-1.11.1.1 openai-1.46.1 orjson-3.10.7 pdf2image-1.17.0 pyclipper-1.3.0.post5 pymupdf-1.24.10 pytesseract-0.3.13 python-bidi-0.6.0 tenacity-8.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb openai langchain langchain_chroma langchain_community langchain_core langchain_openai langchain_text_splitters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkyo8iUdywpQ",
        "outputId": "8422db4a-c690-4eaf-fb17-bf66a993676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.46.1)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_text_splitters\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.123)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.7-py3-none-any.whl (599 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.2/599.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=48d3c27940a0c075eac9f6d524733d492d68f0caad743b09db4aa8c4fd82bb58\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, uvicorn, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain_text_splitters, langchain_openai, langchain, chromadb, langchain_community, langchain_chroma\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.7 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 fastapi-0.115.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-8.4.0 kubernetes-30.1.0 langchain-0.3.0 langchain_chroma-0.1.4 langchain_community-0.3.0 langchain_openai-0.2.0 langchain_text_splitters-0.3.0 marshmallow-3.22.0 mmh3-5.0.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.6.6 pydantic-settings-2.5.2 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.38.5 tiktoken-0.7.0 typing-inspect-0.9.0 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from random import sample\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import chromadb\n",
        "import copy\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from math import floor, ceil\n",
        "import ast\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "GC8iiQP31TQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "TkWaEPQE1qq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_metadata = pd.read_csv('FLARE_Implementation/rmib_dataset/rmib_metadata.csv')\n",
        "df_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "MSSEtZdfhH2f",
        "outputId": "a36b27e0-7b9a-4365-ea7a-46ffbacb93e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     chars  words  lines                           title              type  \\\n",
              "0     3887    721     63                  the sixth cure           chapter   \n",
              "1     6696   1177    118            the walls of babylon           chapter   \n",
              "2   459790  83596   8311                        metadata           chapter   \n",
              "3     3728    665     60                  the third cure           chapter   \n",
              "4     1046    201     77               table of contents  table of contets   \n",
              "5      830    134     14                about the author  about the author   \n",
              "6     1890    306     29                        foreword          foreword   \n",
              "7     2675    471     42                 the fourth cure           chapter   \n",
              "8     5006    916     96                the seventh cure           chapter   \n",
              "9     3901    694     74                 the second cure           chapter   \n",
              "10    9133   1696    160      the five laws of gold full           chapter   \n",
              "11   16343   2996    407   the clay tablets from babylon           chapter   \n",
              "12    2612    478     51                  the fifth cure           chapter   \n",
              "13   11770   1946    169  a historical sketch of babylon           chapter   \n",
              "14   31596   5874    549     the luckiest man in babylon           chapter   \n",
              "15    3745    691     77                  the first cure           chapter   \n",
              "16   20199   3820    335      the richest man in babylon           chapter   \n",
              "17   18833   3605    336     the camel trader of babylon           chapter   \n",
              "18   11576   2107    180        the man who desired gold           chapter   \n",
              "19   31394   5663    581    seven cures for a lean purse           chapter   \n",
              "20  221792  40669   4073      The Richest Man in Babylon         full text   \n",
              "21   22539   4249    397      the gold lender of babylon           chapter   \n",
              "22   24621   4465    400   meet the goddess of good luck           chapter   \n",
              "\n",
              "                                                 text  \n",
              "0   THE SIXTH CURE \\nInsure a future income \\n\\n\"T...  \n",
              "1   The Walls of Babylon \\n\\nOld Banzar, grim warr...  \n",
              "2   ,chars,words,lines,title,type,text\\n9_the_sixt...  \n",
              "3   THE THIRD CURE \\nMake thy gold multiply \\n\\n\"B...  \n",
              "4   Table of Contents \\n\\nAbout the author 3 \\n\\nF...  \n",
              "5   About the author \\n\\nGEORGE SAMUEL CLASON was ...  \n",
              "6   Foreword \\n\\nOur prosperity as a nation depend...  \n",
              "7   THE FOURTH CURE \\nGuard thy treasures from los...  \n",
              "8   THE SEVENTH CURE \\nIncrease thy ability to ear...  \n",
              "9   THE SECOND CURE \\nControl thy expenditures \\n\\...  \n",
              "10  The Five Laws of Gold \\n\\n\"A bag heavy with go...  \n",
              "11  The Clay Tablets From Babylon \\nSt. Swithin's ...  \n",
              "12  THE FIFTH CURE \\nMake of thy dwelling a profit...  \n",
              "13  An Historical Sketch of Babylon \\n\\nIn the pag...  \n",
              "14  The Luckiest Man in Babylon \\n\\nAt the head of...  \n",
              "15  THE FIRST CURE \\nStart thy purse to fattening ...  \n",
              "16  The Richest Man in Babylon \\n\\nIn old Babylon ...  \n",
              "17  The Camel Trader of Babylon \\n\\n\\n\\nThe hungri...  \n",
              "18  The Man Who Desired Gold \\n\\nBansir, the chari...  \n",
              "19  Seven Cures For a Lean Purse \\n\\nThe glory of ...  \n",
              "20  The Richest Man \\nin B abvl o \\n\\n\\n\\n\\nG \\n\\n...  \n",
              "21  The Gold Lender of Babylon \\n\\n\\n\\nFifty piece...  \n",
              "22  Meet the Goddess of Good Luck \\n\\n\"If a man be...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fb465ea-8c88-4dcd-b8f6-975f4850e43d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chars</th>\n",
              "      <th>words</th>\n",
              "      <th>lines</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3887</td>\n",
              "      <td>721</td>\n",
              "      <td>63</td>\n",
              "      <td>the sixth cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE SIXTH CURE \\nInsure a future income \\n\\n\"T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6696</td>\n",
              "      <td>1177</td>\n",
              "      <td>118</td>\n",
              "      <td>the walls of babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Walls of Babylon \\n\\nOld Banzar, grim warr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>459790</td>\n",
              "      <td>83596</td>\n",
              "      <td>8311</td>\n",
              "      <td>metadata</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,chars,words,lines,title,type,text\\n9_the_sixt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3728</td>\n",
              "      <td>665</td>\n",
              "      <td>60</td>\n",
              "      <td>the third cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE THIRD CURE \\nMake thy gold multiply \\n\\n\"B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1046</td>\n",
              "      <td>201</td>\n",
              "      <td>77</td>\n",
              "      <td>table of contents</td>\n",
              "      <td>table of contets</td>\n",
              "      <td>Table of Contents \\n\\nAbout the author 3 \\n\\nF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>830</td>\n",
              "      <td>134</td>\n",
              "      <td>14</td>\n",
              "      <td>about the author</td>\n",
              "      <td>about the author</td>\n",
              "      <td>About the author \\n\\nGEORGE SAMUEL CLASON was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1890</td>\n",
              "      <td>306</td>\n",
              "      <td>29</td>\n",
              "      <td>foreword</td>\n",
              "      <td>foreword</td>\n",
              "      <td>Foreword \\n\\nOur prosperity as a nation depend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2675</td>\n",
              "      <td>471</td>\n",
              "      <td>42</td>\n",
              "      <td>the fourth cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE FOURTH CURE \\nGuard thy treasures from los...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5006</td>\n",
              "      <td>916</td>\n",
              "      <td>96</td>\n",
              "      <td>the seventh cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE SEVENTH CURE \\nIncrease thy ability to ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3901</td>\n",
              "      <td>694</td>\n",
              "      <td>74</td>\n",
              "      <td>the second cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE SECOND CURE \\nControl thy expenditures \\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9133</td>\n",
              "      <td>1696</td>\n",
              "      <td>160</td>\n",
              "      <td>the five laws of gold full</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Five Laws of Gold \\n\\n\"A bag heavy with go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>16343</td>\n",
              "      <td>2996</td>\n",
              "      <td>407</td>\n",
              "      <td>the clay tablets from babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Clay Tablets From Babylon \\nSt. Swithin's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2612</td>\n",
              "      <td>478</td>\n",
              "      <td>51</td>\n",
              "      <td>the fifth cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE FIFTH CURE \\nMake of thy dwelling a profit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11770</td>\n",
              "      <td>1946</td>\n",
              "      <td>169</td>\n",
              "      <td>a historical sketch of babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>An Historical Sketch of Babylon \\n\\nIn the pag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>31596</td>\n",
              "      <td>5874</td>\n",
              "      <td>549</td>\n",
              "      <td>the luckiest man in babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Luckiest Man in Babylon \\n\\nAt the head of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3745</td>\n",
              "      <td>691</td>\n",
              "      <td>77</td>\n",
              "      <td>the first cure</td>\n",
              "      <td>chapter</td>\n",
              "      <td>THE FIRST CURE \\nStart thy purse to fattening ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20199</td>\n",
              "      <td>3820</td>\n",
              "      <td>335</td>\n",
              "      <td>the richest man in babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Richest Man in Babylon \\n\\nIn old Babylon ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18833</td>\n",
              "      <td>3605</td>\n",
              "      <td>336</td>\n",
              "      <td>the camel trader of babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Camel Trader of Babylon \\n\\n\\n\\nThe hungri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11576</td>\n",
              "      <td>2107</td>\n",
              "      <td>180</td>\n",
              "      <td>the man who desired gold</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Man Who Desired Gold \\n\\nBansir, the chari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>31394</td>\n",
              "      <td>5663</td>\n",
              "      <td>581</td>\n",
              "      <td>seven cures for a lean purse</td>\n",
              "      <td>chapter</td>\n",
              "      <td>Seven Cures For a Lean Purse \\n\\nThe glory of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>221792</td>\n",
              "      <td>40669</td>\n",
              "      <td>4073</td>\n",
              "      <td>The Richest Man in Babylon</td>\n",
              "      <td>full text</td>\n",
              "      <td>The Richest Man \\nin B abvl o \\n\\n\\n\\n\\nG \\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22539</td>\n",
              "      <td>4249</td>\n",
              "      <td>397</td>\n",
              "      <td>the gold lender of babylon</td>\n",
              "      <td>chapter</td>\n",
              "      <td>The Gold Lender of Babylon \\n\\n\\n\\nFifty piece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>24621</td>\n",
              "      <td>4465</td>\n",
              "      <td>400</td>\n",
              "      <td>meet the goddess of good luck</td>\n",
              "      <td>chapter</td>\n",
              "      <td>Meet the Goddess of Good Luck \\n\\n\"If a man be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fb465ea-8c88-4dcd-b8f6-975f4850e43d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fb465ea-8c88-4dcd-b8f6-975f4850e43d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fb465ea-8c88-4dcd-b8f6-975f4850e43d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c1ff846-f141-4f7c-bf7d-07ebc136fd6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c1ff846-f141-4f7c-bf7d-07ebc136fd6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c1ff846-f141-4f7c-bf7d-07ebc136fd6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4acec008-af5e-44c7-99db-46e6598ef7fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metadata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4acec008-af5e-44c7-99db-46e6598ef7fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metadata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metadata",
              "summary": "{\n  \"name\": \"df_metadata\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101976,\n        \"min\": 830,\n        \"max\": 459790,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          3745,\n          3901,\n          3887\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18567,\n        \"min\": 134,\n        \"max\": 83596,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          691,\n          694,\n          721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1848,\n        \"min\": 14,\n        \"max\": 8311,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          63,\n          169,\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"the first cure\",\n          \"the second cure\",\n          \"the sixth cure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"table of contets\",\n          \"full text\",\n          \"about the author\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"THE FIRST CURE \\nStart thy purse to fattening \\n\\nArkad addressed a thoughtful man in the second row. \\\"My good friend, at what craft workest \\nthou?\\\" \\n\\n\\\"I,\\\" replied the man, \\\"am a scribe and carve records upon the clay tablets.\\\" \\\"Even at such labor \\ndid I myself earn my first coppers. Therefore, thou hast the same opportunity to build a fortune.\\\" \\n\\nHe spoke to a florid-faced man, farther back. \\\"Pray tell also what dost thou to earn thy bread?\\\" \\n\\n\\\"I,\\\" responded this man, \\\"am a meat butcher. I do buy the goats the farmers raise and kill them \\nand sell the meat to the housewives and the hides to the sandal makers.\\\" \\n\\n\\\"Because thou dost also labor and earn, thou hast every advantage to succeed that I did \\n\\n18 \\n\\n\\n\\npossess. \\n\\nIn this way did Arkad proceed to find out how each man labored to earn his living. When he \\nhad done questioning them, he said: \\n\\n\\\"Now, my students, ye can see that there are many trades and labors at which men may earn \\ncoins. Each of the ways of earning is a stream of gold from which the worker doth divert by his labors a \\nportion to his own purse. Therefore into the purse of each of you flows a stream of coins large or small \\naccording to his ability. Is it not so?\\\" \\n\\nThereupon they agreed that it was so. \\\"Then,\\\" continued Arkad, \\\"if each of you desireth to build \\nfor himself a fortune, is it not wise to start by utilizing that source of wealth which he already has \\nestablished?\\\" \\n\\nTo this they agreed. \\n\\nThen Arkad turned to a humble man who had declared himself an egg merchant. \\\"If thou select \\none of thy baskets and put into it each morning ten eggs and take out from it each evening nine eggs, \\nwhat will eventually happen?\\\" \\n\\n\\\"It will become in time overflowing.\\\" \\n\\n\\\"Why?\\\" \\n\\n\\\"Because each day I put in one more egg than I take out.\\\" \\n\\nArkad turned to the class with a smile. \\\"Does any man here have a lean purse?\\\" \\n\\nFirst they looked amused. Then they laughed. Lastly they waved their purses in jest. \\n\\n\\\"All right,\\\" he continued, \\\"Now I shall tell thee the first remedy I learned to cure a lean purse. \\nDo exactly as I have suggested to the egg merchant. For every ten coins thou placest within thy purse \\ntake out for use but nine. Thy purse will start to fatten at once and its increasing weight will feel good \\nin thy hand and bring satisfaction to thy soul. \\n\\n\\\"Deride not what I say because of its simplicity. Truth is always simple. I told thee I would tell \\nhow built my fortune. This was my beginning. I, too, carried a lean purse and cursed it because there \\nwas naught within to satisfy my desires. But when I began to take out from my purse but nine parts of \\nten I put in, it began to fatten. So will thine. \\n\\n\\\"Now I will tell a strange truth, the reason for which I know not. When I ceased to pay out \\nmore than nine-tenths of my earnings, I managed to get along just as well. I was not shorter than \\nbefore. Also, ere long, did coins come to me more easily than before. Surely it is a law of the Gods that \\nunto him who keepeth and spendeth not a certain part of all his earnings, shall gold come more easily. \\nLikewise, him whose purse is empty does gold avoid. \\n\\n\\\"Which desirest thou the most? Is it the gratification of thy desires of each day, a jewel, a bit of \\nfinery, better raiment, more food; things quickly gone and forgotten? Or is it substantial belongings, \\ngold, lands, herds, merchandise, income-bringing investments? The coins thou takest from thy purse \\nbring the first. The coins thou leavest within it will bring the latter. \\n\\n\\\"This, my students, was the first cure I did discover for my lean purse: 'For each ten coins I put \\nin, to spend but nine.' Debate this amongst yourselves. If any man proves it untrue, tell me upon the \\nmorrow when we shall meet again.\\\" \\n\\n\\n\\n\",\n          \"THE SECOND CURE \\nControl thy expenditures \\n\\n19 \\n\\n\\n\\n\\\"Some of your members, my students, have asked me this: How can a man keep one-tenth of all \\nhe earns in his purse when all the coins he earns are not enough for his necessary expenses?\\\" So did \\nArkad address his students upon the second day \\n\\n\\\"Yesterday how many of thee carried lean purses?\\\" \\n\\n\\\"All of us,\\\" answered the class. \\n\\n\\\"Yet, thou do not all earn the same. Some earn much more than others. Some have much larger \\nfamilies to support. Yet, all purses were equally lean. Now I will tell thee an unusual truth about men \\nand sons of men. It is this; That what each of us calls our 'necessary expenses' will always grow to \\nequal our incomes unless we protest to the contrary. \\n\\n\\\"Confuse not the necessary expenses with thy desires. Each of you, together with your good \\nfamilies, have more desires than your earnings can gratify. Therefore are thy earnings spent to gratify \\nthese desires insofar as they will go. Still thou retainest many ungratified desires. \\n\\n\\\"All men are burdened with more desires than they can gratify. Because of my wealth thinkest \\nthou I may gratify every desire? Tis a false idea. There are limits to my time. There are limits to my \\nstrength. There are limits to the distance I may travel. There are limits to what I may eat. There are \\nlimits to the zest with which I may enjoy. \\n\\n\\\"I say to you that just as weeds grow in a field wherever the farmer leaves space for their roots, \\neven so freely do desires grow in men whenever there is a possibility of their being gratified. Thy \\ndesires are a multitude and those that thou mayest gratify are but few. \\n\\n\\\"Study thoughtfully thy accustomed habits of living. Herein may be most often found certain \\naccepted expenses that may wisely be reduced or eliminated. Let thy motto be one hundred percent of \\nappreciated value demanded for each coin spent. \\n\\n\\\"Therefore, engrave upon the clay each thing for which thou desireth to spend. Select those that \\nare necessary and others that are possible through the expenditure of nine- tenths of thy income. Cross \\nout the rest and consider them but a part of that great multitude of desires that must go unsatisfied and \\nregret them not. \\n\\n\\\"Budget then thy necessary expenses. Touch not the one- tenth that is fattening thy purse. Let \\nthis be thy great desire that is being fulfilled. Keep working with thy budget, keep adjusting it to help \\nthee. Make it thy first assistant in defending thy fattening purse.\\\" \\n\\nHereupon one of the students, wearing a robe of red and gold, arose and said, \\\"I am a free man. \\nI believe that it is my right to enjoy the good things of life. Therefore do I rebel against the slavery of a \\nbudget which determines just how much I may spend and for what. I feel it would take much pleasure \\nfrom my life and make me little more than a pack- ass to carry a burden.\\\" \\n\\nTo him Arkad replied, \\\"Who, my friend, would determine thy budget?\\\" \\n\\n\\\"I would make it for myself,\\\" responded the protesting one. \\n\\n\\\"In that case were a pack-ass to budget his burden would he include therein jewels and rugs and \\nheavy bars of gold? Not so. He would include hay and grain and a bag of water for the desert trail. \\n\\n\\\"The purpose of a budget is to help thy purse to fatten. It is to assist thee to have thy necessities \\nand, insofar as attainable, thy other desires. It is to enable thee to realize thy most cherished desires by \\ndefending them from thy casual wishes. Like a bright light in a dark cave thy budget shows up the leaks \\nfrom thy purse and enables thee to stop them and control thy expenditures for definite and gratifying \\npurposes. \\n\\n\\\"This, then, is the second cure for a lean purse. Budget thy 43expenses that thou mayest have \\ncoins to pay for thy necessities, to pay for thy enjoyments and to gratify thy worthwhile desires without \\nspending more than nine-tenths of thy earnings.\\\" \\n\\n\\n\\n20 \\n\\n\\n\\n\",\n          \"THE SIXTH CURE \\nInsure a future income \\n\\n\\\"The life of every man proceedeth from his childhood to his old age. This is the path of life and \\nno man may deviate from it unless the Gods call him prematurely to the world beyond. Therefore do I \\nsay that it behooves a man to make preparation for a suitable income in the days to come, when he is no \\nlonger young, and to make preparations for his family should he be no longer with them to comfort and \\nsupport them. This lesson shall instruct thee in providing a full purse when time has made thee less able \\nto learn.\\\" So Arkad addressed his class upon the sixth day. \\n\\n\\\"The man who, because of his understanding of the laws of wealth, acquireth a growing \\nsurplus, should give thought to those future days. He should plan certain investments or provision that \\nmay endure safely for many years, yet will be available when the time arrives which he has so wisely \\nanticipated. \\n\\n\\\"There are diverse ways by which a man may provide with safety for his future. He may \\nprovide a hiding place and there bury a secret treasure. Yet, no matter with what skill it be hidden, it \\nmay nevertheless become the loot of thieves. For this reason I recommend not this plan. \\n\\n\\\"A man may buy houses or lands for this purpose. If wisely chosen as to their usefulness and \\n\\n23 \\n\\n\\n\\nvalue in the future, they are permanent in their value and their earnings or their sale will provide well \\nfor his purpose. \\n\\n\\\"A man may loan a small sum to the money lender and increase it at regular periods. The rental \\nwhich the money lender adds to this will largely add to its increase. I do know a sandal maker, named \\nAnsan, who explained to me not long ago that each week for eight years he had deposited with his \\nmoney lender two pieces of silver. The money lender had but recently given him an accounting over \\nwhich he greatly rejoiced. The total of his small deposits with their rental at the customary rate of one- \\nfourth their value for each four years, had now become a thousand and forty pieces of silver. \\n\\n\\\"I did gladly encourage him further by demonstrating to him with my knowledge of the \\nnumbers that in twelve years more, if he would keep his regular deposits of but two pieces of silver \\neach week, the money lender would then owe him four thousand pieces of silver, a worthy competence \\nfor the rest of his life. \\n\\n\\\"Surely, when such a small payment made with regularity doth produce such profitable results, \\nno man can afford not to insure a treasure for his old age and the protection of his family, no matter \\nhow prosperous his business and his investments may be. \\n\\n\\\"I would that I might say more about this. In my mind rests a belief that some day wise- \\nthinking men will devise a plan to insure against death whereby many men pay in but a trifling sum \\nregularly, the aggregate making a handsome sum for the family of each member who passeth to the \\nbeyond. This do I see as something desirable and which I could highly recommend. \\n\\nBut today it is not possible because it must reach beyond the life of any man or any partnership \\nto operate. It must be as stable as the King's throne. Some day do I feel that such a plan shall come to \\npass and be a great blessing to many men, because even the first small payment will make available a \\nsnug fortune for the family of a member should he pass on. \\n\\n\\\"But because we live in our own day and not in the days which are to come, must we take \\nadvantage of those means and ways of accomplishing our purposes. Therefore do I recommend to all \\nmen, that they, by wise and well thought out methods, do provide against a lean purse in their mature \\nyears. For a lean purse to a man no longer able to earn or to a family without its head is a sore tragedy. \\n\\\"This, then, is the sixth cure for a lean purse. Provide in advance for the needs of thy growing age and \\nthe protection of thy family.\\\" \\n\\n\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flare(question, retriever, openai_api_key, openai_model='gpt-4o-mini', tolerance=-0.4, verbose=True):\n",
        "    '''\n",
        "    Uses a advanced RAG technique called FLARE to answer the question. It's an implementation\n",
        "    of the paper: \"Active Retrieval Augmented Generation\" Jiang ZB and fellow scientists in October\n",
        "    2023.\n",
        "\n",
        "    Args:\n",
        "      question: The question to be answered.\n",
        "      retriever: langchain retriever to be used.\n",
        "      openai_api_key: The OPENAI API key to be used.\n",
        "      openai_model: OpenAI Model to use\n",
        "      tolerance: The tolerance of logprobs to be marked as uncertain\n",
        "    Returns:\n",
        "      The answer to the question.\n",
        "\n",
        "    '''\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    # getting the first output, normal rag\n",
        "    # get context\n",
        "    context = retriever.get_relevant_documents(question)\n",
        "\n",
        "    # constructing message\n",
        "    message = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a book expert that answers questions about books. Use the following pieces of retrieved context to answer the question.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "        Context: {format_docs(context)}\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"}\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Acquiring answer with traditional RAG...')\n",
        "    # answer the question\n",
        "    answer = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "        logprobs=True,\n",
        "    )\n",
        "\n",
        "    if verbose: print(f'Finding uncertain tokens, and annotating the answer...')\n",
        "    # annotate the question\n",
        "    annotated_answer = uncertain_marker(annotated_combiner(annotater(sequential_combine(\n",
        "        combine_token_to_word(answer), 5, np.mean), tolerance=tolerance), np.mean))\n",
        "\n",
        "    # constructing the questions for the uncertained answers\n",
        "    message += [\n",
        "        {\"role\": \"assistant\", \"content\": answer.choices[0].message.content},\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"Now, I have marked the answer to where you are uncertain with the phrases. For every, phrases in between\n",
        "        [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)].\n",
        "\n",
        "        This question is going to be used independently to get get relevant texts from a vector database\n",
        "        It's critical that the question includes the object and subject of the phrase\n",
        "        It's critical that the question has context about the annswer\n",
        "\n",
        "\n",
        "        First example:\n",
        "        user: What is meaning of the colors in the flag of Ghana?\n",
        "        assistant: Red is for the blood of martyrs, green for forests, and gold for mineral wealth.\n",
        "        user: Here's the annotated version: ([uncertain] Red [/uncertain]) is for the blood of martyrs, ([uncertain] green for forests [/uncertain]), and gold for mineral wealth.\n",
        "        assistant: [Search(is red a color in the flag of Ghana?)] is for the blood of martyrs, [Search(is green a color in the flag of Ghana? If so, what does it symbolize?)], and gold for mineral wealth.\n",
        "\n",
        "        Second example:\n",
        "        user: Give me a very short summary of Joe Biden's journey becoming the president!\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on August 18, 2019. His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        user: Here's an annotated version: Joe Biden announced his candidacy for the 2020 presidential election on ([uncertain] August 18, 2019 [/uncertain]). His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on [Search(When did Joe Biden announce his candidancy for the 2020 presidential election?)].  His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        \"\"\"},\n",
        "        {\"role\": \"user\",\n",
        "            \"content\": f\"Here's the annotated version: {annotated_answer.choices[0].message.content}\"},\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Constructing questions for the annotated tokens...')\n",
        "    questions_construction = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "    )\n",
        "\n",
        "    # extracting the questions\n",
        "    message += [\n",
        "        {\"role\": \"assistant\",\n",
        "            \"content\": questions_construction.choices[0].message.content},\n",
        "        {'role': \"user\", \"content\": \"\"\"Now for all the questions marked as [Search(question)], please extract them in a python dictionary format:\n",
        "        {\n",
        "        \"1\": \"question 1\",\n",
        "        \"2\": \"question 2\",\n",
        "        ...\n",
        "        \"n\": \"question n\"\n",
        "        }\n",
        "\n",
        "        It is critical to only output the dictionary and nothing else.\n",
        "        It is critical to not output it in a markdown format.\n",
        "        It is critical that the first character of the output starts with an open curly bracket '{'\n",
        "      \"\"\"}\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Extracting constructed questions...')\n",
        "    questions = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "    )\n",
        "    retry_count= 1\n",
        "    try:\n",
        "        questions_dict = ast.literal_eval(questions.choices[0].message.content)\n",
        "    except:\n",
        "        while retry_count <= 3:\n",
        "            if verbose: print(f\"Couldn't convert to dictionary, attempting to fix the dictionary. Retry count: {retry_count}\")\n",
        "            questions = client.chat.completions.create(\n",
        "                model=openai_model,\n",
        "                messages=message,\n",
        "            )\n",
        "            try:\n",
        "                questions_dict = ast.literal_eval(questions.choices[0].message.content)\n",
        "                break\n",
        "            except:\n",
        "                retry_count += 1\n",
        "                continue\n",
        "        else:\n",
        "            print(f'FLARE Failed, try to call the function again.')\n",
        "            return\n",
        "\n",
        "    # message to answer the questions one by one\n",
        "    new_message = [\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"You are a book expert that answers questions about books.\n",
        "      Question: {question}\n",
        "      Context: called the RAG\n",
        "      Original Answer: {answer.choices[0].message.content}\n",
        "\n",
        "      Now, I have marked the answer to where you are uncertain with the phrases. For every, phrases in between\n",
        "      [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)]\n",
        "\n",
        "      Annotated Answer: {annotated_answer.choices[0].message.content}\n",
        "      Constructed Questions Answer: {questions_construction.choices[0].message.content}\n",
        "      \"\"\"},\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Answering each questions...')\n",
        "    # answering each of the questions one by one\n",
        "    constructed_question_answer = {}\n",
        "    for i in range(1, len(questions_dict) + 1):\n",
        "        question_temp = questions_dict[str(i)]\n",
        "\n",
        "        # getting the context for the question\n",
        "        context = retriever.get_relevant_documents(question_temp)\n",
        "\n",
        "        # constructing the question and context message\n",
        "        question_string = f\"\"\"Use the following pieces of retrieved context to answer the question.\n",
        "        Question: {question}\n",
        "        Context: {format_docs(context)}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        question_message = new_message + \\\n",
        "            [{\"role\": \"user\", \"content\": question_string}]\n",
        "\n",
        "        # answering the question\n",
        "        question_answer = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=question_message,\n",
        "        )\n",
        "        constructed_question_answer[str(i)] = [\n",
        "            question_temp, question_answer.choices[0].message.content]\n",
        "\n",
        "    # reconstructing to get the final answer\n",
        "    question_answer = \"\"\n",
        "    for i in range(1, len(questions_dict) + 1):\n",
        "        question_answer += f\"\"\"Question: {questions_dict[str(i)]}\\nAnswer: {constructed_question_answer[str(i)][1]}\\n\"\"\"\n",
        "\n",
        "    reconstructing = f\"\"\"\n",
        "    Here are the questions and their answers:\n",
        "    {question_answer}\n",
        "    Now with answers to those questions and the original question: {question}, improve the original answer without changing the format of the answer.\n",
        "\n",
        "    Notes:\n",
        "    It's critical to just output the final answer.\n",
        "    It's critical to not output the annotated answer.\n",
        "    It's critical to not output constructed questions answer.\n",
        "\n",
        "    Final Answer:\n",
        "    \"\"\"\n",
        "    reconstructing_message = new_message + \\\n",
        "        [{\"role\": \"user\", \"content\": reconstructing}]\n",
        "    if verbose: print(f'Reconstructing the final answer...')\n",
        "    reconstructed_answer = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=reconstructing_message,\n",
        "    )\n",
        "\n",
        "    # printing some information\n",
        "    # It prints the question construction for the annotated answer because it's clearer to make the annotations as the questions itself\n",
        "    return answer, questions_construction, reconstructed_answer = pd.read_csv('FLARE_Implementation/questions', index_col=['chapter', 'index'])"
      ],
      "metadata": {
        "id": "Bc9Ark54EJx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = df_questions.loc['meet the goddess of good luck', 0]['hard']\n",
        "print(question)"
      ],
      "metadata": {
        "id": "w4SyuiAV2uZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f47e500-5fd6-4370-82bd-fd46ccd4c3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did Arkad believe that good luck follows opportunity?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLARE Implementation\n",
        "From the paper, here's the approaches I'm going to make based on the paper.\n",
        "1. Use the LLM for traditional RAG or regular querying to answer the question\n",
        "2. Check logits for each token from the LLM and annotate with a symbol any where the llm is not confident.\n",
        "3. Constructing questions to get a more confident answer for that token.\n",
        "4. Answer these questions\n",
        "5. Reconstruct the Answer"
      ],
      "metadata": {
        "id": "VpMCinDrblaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "vUs5SokfjMOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Fake_Retriever:\n",
        "  '''\n",
        "  Instead of a vector database. FLARE can be used for regular zero-shot\n",
        "  prompting. If the context is relatively not too long, it may be better\n",
        "  to just give the whole context to the LLM at all cases.\n",
        "\n",
        "  The class Fake_Retriever returns the whole context everytime a retriever\n",
        "  is called.\n",
        "  '''\n",
        "  def __init__(self, data):\n",
        "    self.data = Document(page_content=data)\n",
        "  def get_relevant_documents(self, query):\n",
        "    return [self.data]\n",
        "\n",
        "\n",
        "def logprobs_simple_print(response, n=None):\n",
        "    \"\"\"\n",
        "    Prints an OpenAI response with logprobs for each tokens\n",
        "\n",
        "    Args:\n",
        "      response: OpenAI Response object with logprobs\n",
        "      n: First n tokens to print\n",
        "    \"\"\"\n",
        "    for i, token_data in enumerate(response.choices[0].logprobs.content[:n]):\n",
        "        print(f'{i}: {token_data.token}')\n",
        "        print(token_data.bytes)\n",
        "        if hasattr(token_data, 'uncertain'):\n",
        "            print(f'{token_data.logprob}\\t{str(token_data.uncertain)}')\n",
        "        else:\n",
        "            print(f'{token_data.logprob}')\n",
        "        print('\\n')\n",
        "\n",
        "\n",
        "def logprobs_pretty_print(response, prompt):\n",
        "    \"\"\"\n",
        "    Pretty prints an OpenAI response with logprobs for each tokens\n",
        "\n",
        "    Args:\n",
        "      response: OpenAI Response object with logprobs\n",
        "      prompt: Original Prompt\n",
        "    \"\"\"\n",
        "    logprobs = [token.logprob for token in response.choices[0].logprobs.content]\n",
        "    response_text = response.choices[0].message.content\n",
        "    response_text_tokens = [\n",
        "        token.token for token in response.choices[0].logprobs.content]\n",
        "    if hasattr(response.choices[0].logprobs.content[0], 'uncertain'):\n",
        "        uncertainty = [\n",
        "            token.uncertain for token in response.choices[0].logprobs.content]\n",
        "\n",
        "    max_starter_length = max(\n",
        "        len(s) for s in [\"Prompt:\", \"Response:\", \"Tokens:\", \"Logprobs:\", \"Perplexity:\"])\n",
        "    max_token_length = max(len(s) for s in response_text_tokens)\n",
        "\n",
        "    new_lines_index = []\n",
        "    for i, token in enumerate(response_text_tokens):\n",
        "        if '\\n' in token:\n",
        "            new_lines_index += [i]\n",
        "    formatted_response_tokens = [\n",
        "        s.rjust(max_token_length) for s in response_text_tokens]\n",
        "    formatted_lps = [f\"{lp:.2f}\".rjust(max_token_length) for lp in logprobs]\n",
        "    formatted_linear_probs = [\n",
        "        f\"{np.round(np.exp(lp)*100,2):.2f}%\".rjust(max_token_length) for lp in logprobs]\n",
        "    if hasattr(response.choices[0].logprobs.content[0], 'uncertain'):\n",
        "        formatted_uncertain = [str(uncertain).rjust(\n",
        "            max_token_length) for uncertain in uncertainty]\n",
        "    perplexity_score = np.exp(-np.mean(logprobs))\n",
        "    print(\"Prompt:\".ljust(max_starter_length), prompt)\n",
        "    print(\"Response:\".ljust(max_starter_length), response_text, \"\\n\")\n",
        "    print(\"=\" * 150)\n",
        "    cut_off_start = 0\n",
        "    cut_off_end = 0\n",
        "    for i, new_line_index in enumerate(new_lines_index):\n",
        "        cut_off_start = 0 if i == 0 else new_lines_index[i - 1] + 1\n",
        "        cut_off_end = new_lines_index[i] + 1\n",
        "        print(\"Tokens:\".ljust(max_starter_length), \" \".join(\n",
        "            formatted_response_tokens[cut_off_start:cut_off_end]))\n",
        "        print(\"Logprobs:\".ljust(max_starter_length), \" \".join(\n",
        "            formatted_lps[cut_off_start:cut_off_end]))\n",
        "        print(\"Linprob:\".ljust(max_starter_length), \" \".join(\n",
        "            formatted_linear_probs[cut_off_start:cut_off_end]))\n",
        "        if hasattr(response.choices[0].logprobs.content[0], 'uncertain'):\n",
        "            print(\"Uncertainty:\".ljust(max_starter_length), \" \".join(\n",
        "                formatted_uncertain[cut_off_start:cut_off_end]))\n",
        "        print(\"=\" * 150)\n",
        "    print(\"Tokens:\".ljust(max_starter_length), \" \".join(\n",
        "        formatted_response_tokens[cut_off_end:]))\n",
        "    print(\"Logprobs:\".ljust(max_starter_length),\n",
        "          \" \".join(formatted_lps[cut_off_end:]))\n",
        "    print(\"Linprob:\".ljust(max_starter_length),\n",
        "          \" \".join(formatted_linear_probs[cut_off_end:]))\n",
        "    if hasattr(response.choices[0].logprobs.content[0], 'uncertain'):\n",
        "        print(\"Uncertainty:\".ljust(max_starter_length),\n",
        "              \" \".join(formatted_uncertain[cut_off_end:]))\n",
        "\n",
        "    print(\"=\" * 150)\n",
        "    print(\"Perplexity:\".ljust(max_starter_length), perplexity_score, \"\\n\")\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    '''\n",
        "    formats the list of documents into a string\n",
        "\n",
        "    Args:\n",
        "      docs: list of documents\n",
        "\n",
        "    Returns:\n",
        "      string of documents\n",
        "    '''\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def combine_token_to_word(response):\n",
        "    \"\"\"\n",
        "    Combines the tokens in an OpenAI response that are parts of words, into a word.\n",
        "\n",
        "    Args:\n",
        "        response: OpenAI response object\n",
        "\n",
        "    Returns:\n",
        "        Open AI Response object\n",
        "    \"\"\"\n",
        "    temp_response = copy.deepcopy(response)\n",
        "    new_logprobs_list = []\n",
        "    new_logprob = temp_response.choices[0].logprobs.content[0]\n",
        "    skip_next = False\n",
        "    for i, token_data in enumerate(temp_response.choices[0].logprobs.content):\n",
        "        if (i == 0) or (skip_next):\n",
        "            if skip_next:\n",
        "                skip_next = False\n",
        "            continue\n",
        "        if '\\n' in token_data.token:\n",
        "            new_logprob.token += token_data.token\n",
        "            new_logprob.bytes += token_data.bytes\n",
        "            new_logprob.logprob = min(new_logprob.logprob, token_data.logprob)\n",
        "            new_logprob.top_logprobs += token_data.top_logprobs\n",
        "            new_logprobs_list.append(new_logprob)\n",
        "            new_logprob = temp_response.choices[0].logprobs.content[i + 1]\n",
        "            skip_next = True\n",
        "            continue\n",
        "        if token_data.bytes[0] == 32:\n",
        "            new_logprobs_list.append(new_logprob)\n",
        "            new_logprob = token_data\n",
        "        else:\n",
        "            new_logprob.token += token_data.token\n",
        "            new_logprob.bytes += token_data.bytes\n",
        "            new_logprob.logprob = min(new_logprob.logprob, token_data.logprob)\n",
        "            new_logprob.top_logprobs += token_data.top_logprobs\n",
        "        if i == (len(temp_response.choices[0].logprobs.content) - 1):\n",
        "            new_logprobs_list.append(new_logprob)\n",
        "    temp_response.choices[0].logprobs.content = new_logprobs_list\n",
        "    return temp_response\n",
        "\n",
        "\n",
        "def split(list, n):\n",
        "    \"\"\"\n",
        "    Given a list, it returns a new list of n-sized lists. The items in each\n",
        "    n-sized list is determined by the order of the original list.\n",
        "\n",
        "    Args:\n",
        "        list: a Python list\n",
        "        n: int\n",
        "\n",
        "    Return:\n",
        "        A list of n-sized lists\n",
        "    \"\"\"\n",
        "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
        "\n",
        "\n",
        "def token_data_group_sequeeze(token_data_list, aggregate_func):\n",
        "    \"\"\"\n",
        "    Given a list of Open AI token data, it squeezes it into one token. All the token will\n",
        "    be concatenated, the bytes will be concatenated, the logprob will be determined by\n",
        "    the aggregate_func, and the logprobs will be concatenated.\n",
        "\n",
        "    Args:\n",
        "        token_data_list: a list of Open AI token data objects\n",
        "        aggregate_func: a function that accepts n-numbers of int as it's argument and returns an int\n",
        "\n",
        "    Returns:\n",
        "        An Open AI token data object\n",
        "    \"\"\"\n",
        "    new_logprob = copy.deepcopy(token_data_list[0])\n",
        "    new_logprob.token = ''.join(\n",
        "        [token_data.token for token_data in token_data_list])\n",
        "    new_logprob.bytes = [\n",
        "        byte for token_data in token_data_list for byte in token_data.bytes]\n",
        "    new_logprob.logprob = aggregate_func(\n",
        "        [token_data.logprob for token_data in token_data_list])\n",
        "    new_logprob.top_logprobs = [\n",
        "        top_logprob for token_data in token_data_list for top_logprob in token_data.top_logprobs]\n",
        "    if hasattr(token_data_list[0], 'uncertain'):\n",
        "        new_logprob.uncertain = token_data_list[0].uncertain\n",
        "    return new_logprob\n",
        "\n",
        "\n",
        "def sequential_combine(response, mode, aggregate_func=min):\n",
        "    \"\"\"\n",
        "    Given an OpenAI response object with logprobs, combines the token_data list\n",
        "    into groups of size mode. The method to combine the logprobs value is determined\n",
        "    by the aggregate_func.\n",
        "\n",
        "    Args:\n",
        "        response: OpenAI response object\n",
        "        mode: int\n",
        "        aggregate_func: a function that accepts n-numbers of int as it's argument and returns an int\n",
        "\n",
        "    Returns:\n",
        "        An OpenAI Response object\n",
        "    \"\"\"\n",
        "    temp_response = copy.deepcopy(response)\n",
        "    skip_next = False\n",
        "    logprobs = temp_response.choices[0].logprobs.content\n",
        "\n",
        "    # split by sentences\n",
        "    sentences = []\n",
        "    start = 0\n",
        "    total_token = 0\n",
        "    for i, token_data in enumerate(logprobs):\n",
        "        if ('\\n' in token_data.token) or ('.' in token_data.token) or ('?' in token_data.token) or ('!' in token_data.token):\n",
        "            sentences += [logprobs[start: i + 1]]\n",
        "            total_token += len(logprobs[start: i + 1])\n",
        "            start = i + 1\n",
        "    if total_token != len(logprobs):\n",
        "        sentences += [logprobs[start:]]\n",
        "        total_token += len(logprobs[start:])\n",
        "\n",
        "    log_probs_list = []\n",
        "    # splits the sentences by words, and group them based on mode\n",
        "    if isinstance(mode, int):\n",
        "        for sentence in sentences:\n",
        "            grouped_sentence = split(sentence, mode)\n",
        "            for group in grouped_sentence:\n",
        "                log_probs_list += [\n",
        "                    token_data_group_sequeeze(group, aggregate_func)]\n",
        "        temp_response.choices[0].logprobs.content = log_probs_list\n",
        "    return temp_response"
      ],
      "metadata": {
        "id": "RXBGPJ9LVAgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 and 2. Querying the LLM and Combining Tokens\n",
        "The tokens where the LLM will re-check will first be combined into either a word, a phrase, or a sentence."
      ],
      "metadata": {
        "id": "LiuXj3HkNkOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Richest Man in Babylon"
      ],
      "metadata": {
        "id": "OskIIjNFvNiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful and book expert that answers questions about the book \"},\n",
        "        {\"role\": \"user\", \"content\": 'Who is the author of the book \"The Richest Man in Babylon\"?'},\n",
        "        {\"role\": \"assistant\", \"content\": 'The author of \"The Richest Man in Babylon\" is George S. Clason. The book, first published in 1926, offers financial advice through a collection of parables set in ancient Babylon.'},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "      ],\n",
        "      logprobs=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "WKB9Fdi6Qzas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8VXSBCxRuI3",
        "outputId": "48c5830d-daae-48d1-e4a8-5c0cef605426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(response, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezlj_PwASQxz",
        "outputId": "581d7c40-89df-459e-96bf-6f132ce2990c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                 In              \"            The           Rich            est            Man             in        Babylon             ,\"            Ark             ad              ,            who             is            the        richest            man             in        Babylon              ,       believes           that           good           luck        follows    opportunity        because             he           sees           luck             as              a             by        product             of            one             ’s      readiness             to          seize  opportunities           when           they          arise              .             He       explains           that           many         people          often           miss        chances             to         become        wealthy        because           they           fail             to      recognize             or            act           upon            the  opportunities      presented             to           them              .             \n",
            "\n",
            "\n",
            "Logprobs:            -0.05          -0.00           0.00           0.00           0.00           0.00           0.00           0.00          -0.00          -0.00          -0.00          -0.57          -1.70          -0.28          -0.28          -1.15          -0.00          -0.00          -0.03          -0.01          -0.24           0.00          -0.00           0.00          -0.00          -0.00          -0.01          -0.00          -1.33          -0.31          -0.02          -0.25          -1.81          -0.00          -0.00          -5.79          -0.02          -1.73          -0.16          -0.45          -0.17          -0.13           0.00          -0.01          -0.00          -0.36          -1.35          -0.00          -1.75          -0.01          -1.98          -1.80          -2.34          -1.26          -3.90          -0.18          -0.23          -0.00          -2.35          -0.00          -0.26          -0.36          -0.06          -0.39          -1.71          -0.01          -0.52          -0.00           0.00          -0.48          -0.28\n",
            "Linprob:            95.26%        100.00%        100.00%        100.00%        100.00%        100.00%        100.00%        100.00%        100.00%         99.99%        100.00%         56.64%         18.24%         75.47%         75.83%         31.79%        100.00%        100.00%         97.07%         98.90%         78.93%        100.00%         99.96%        100.00%         99.77%        100.00%         99.26%         99.90%         26.53%         73.54%         97.70%         77.81%         16.30%         99.94%        100.00%          0.30%         98.37%         17.71%         85.20%         63.50%         84.58%         88.11%        100.00%         98.58%        100.00%         70.00%         26.04%         99.87%         17.40%         99.38%         13.81%         16.60%          9.66%         28.49%          2.02%         83.35%         79.17%         99.99%          9.57%        100.00%         77.16%         69.85%         94.35%         67.89%         18.03%         99.21%         59.75%        100.00%        100.00%         62.12%         75.72%\n",
            "======================================================================================================================================================\n",
            "Tokens:                 Ar            kad       suggests           that          those            who            are       diligent              ,       prepared              ,            and        willing             to           work         toward          their          goals            are           more         likely             to      encounter  opportunities           that           lead             to        success              .             In        essence              ,             he     emphasizes           that           luck             is            not         merely         random         chance              ;         rather              ,             it             is        created        through         effort              ,    willingness             to           take          risks              ,            and            the        ability             to      recognize            and            act             on        chances           that           life       presents              .           This    perspective     encourages        readers             to             be      proactive            and             to           seek            out  opportunities              ,         rather           than        relying         solely             on         chance            for      financial        success              .\n",
            "Logprobs:            -0.01          -0.00          -3.05          -0.00          -0.88          -0.00          -0.77          -1.54          -0.13          -0.59          -0.00          -0.00          -1.38          -0.00          -3.68          -3.22          -0.00          -0.20          -0.28          -0.00          -0.00          -0.00          -0.07          -1.56          -0.66          -0.71          -0.00          -0.25          -0.14          -1.04          -0.67          -0.00          -0.10          -1.12          -0.25          -1.25          -0.14          -0.01          -0.58          -1.38          -0.40          -1.32          -0.41          -0.00          -0.01          -0.28          -2.01          -0.60          -2.52          -0.13       -9999.00          -0.03          -0.42          -0.11          -0.00          -0.00          -0.18          -0.47          -0.00          -0.36          -0.24          -0.19          -0.27          -5.38          -1.29          -3.74          -0.33          -0.00          -0.13          -1.24          -0.24          -0.42          -0.00          -0.81          -0.00          -0.77          -0.62          -4.26          -0.07          -0.15          -1.64          -1.45           0.00          -4.29          -0.44          -0.00          -2.71          -0.24          -0.84          -0.02          -0.00\n",
            "Linprob:            99.21%        100.00%          4.72%        100.00%         41.43%         99.99%         46.35%         21.39%         87.94%         55.48%         99.99%        100.00%         25.28%        100.00%          2.53%          3.99%         99.63%         81.74%         75.60%         99.51%         99.99%        100.00%         93.45%         21.07%         51.54%         49.00%         99.98%         77.82%         87.24%         35.32%         51.09%        100.00%         90.15%         32.68%         77.68%         28.57%         87.30%         99.48%         55.80%         25.13%         67.33%         26.83%         66.08%        100.00%         98.58%         75.31%         13.40%         55.01%          8.06%         88.08%          0.00%         97.40%         65.82%         89.78%        100.00%         99.99%         83.46%         62.55%        100.00%         69.47%         78.45%         82.84%         76.70%          0.46%         27.59%          2.38%         71.88%         99.57%         87.65%         29.04%         78.84%         65.83%         99.99%         44.65%         99.96%         46.45%         53.95%          1.42%         93.33%         86.42%         19.41%         23.54%        100.00%          1.37%         64.68%        100.00%          6.66%         78.48%         43.21%         97.72%         99.73%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.219849018437654e+27 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the LLM is unsure with some of the tokens. However, some of the tokens are not words, for instance, it seems to split \"Arkad\" into 2 tokens: \"Ark\" and \"ad\". Let's combine the tokens that are half words, and set the logprobs as the lowest among them."
      ],
      "metadata": {
        "id": "eSB4E1xpWh09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(combine_token_to_word(response), question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmAqivWjL2Uj",
        "outputId": "9efab38e-ba04-40c2-940f-db9883bba376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                  In            \"The         Richest             Man              in       Babylon,\"          Arkad,             who              is             the         richest             man              in        Babylon,        believes            that            good            luck         follows     opportunity         because              he            sees            luck              as               a       byproduct              of           one’s       readiness              to           seize   opportunities            when            they          arise.              He        explains            that            many          people           often            miss         chances              to          become         wealthy         because            they            fail              to       recognize              or             act            upon             the   opportunities       presented              to        them. \n",
            "\n",
            "\n",
            "Logprobs:             -0.05           -0.00            0.00            0.00            0.00           -0.00           -0.57           -1.70           -0.28           -0.28           -1.15           -0.00           -0.00           -0.03           -0.24            0.00           -0.00            0.00           -0.00           -0.00           -0.01           -0.00           -1.33           -0.31           -0.02           -0.25           -1.81           -0.00           -5.79           -1.73           -0.16           -0.45           -0.17           -0.13            0.00           -0.01           -0.36           -1.35           -0.00           -1.75           -0.01           -1.98           -1.80           -2.34           -1.26           -3.90           -0.18           -0.23           -0.00           -2.35           -0.00           -0.26           -0.36           -0.06           -0.39           -1.71           -0.01           -0.52           -0.00           -0.48\n",
            "Linprob:             95.26%         100.00%         100.00%         100.00%         100.00%         100.00%          56.64%          18.24%          75.47%          75.83%          31.79%         100.00%         100.00%          97.07%          78.93%         100.00%          99.96%         100.00%          99.77%         100.00%          99.26%          99.90%          26.53%          73.54%          97.70%          77.81%          16.30%         100.00%           0.30%          17.71%          85.20%          63.50%          84.58%          88.11%         100.00%          98.58%          70.00%          26.04%          99.87%          17.40%          99.38%          13.81%          16.60%           9.66%          28.49%           2.02%          83.35%          79.17%          99.99%           9.57%         100.00%          77.16%          69.85%          94.35%          67.89%          18.03%          99.21%          59.75%         100.00%          62.12%\n",
            "======================================================================================================================================================\n",
            "Tokens:               Arkad        suggests            that           those             who             are       diligent,       prepared,             and         willing              to            work          toward           their           goals             are            more          likely              to       encounter   opportunities            that            lead              to        success.              In        essence,              he      emphasizes            that            luck              is             not          merely          random         chance;         rather,              it              is         created         through         effort,     willingness              to            take          risks,             and             the         ability              to       recognize             and             act              on         chances            that            life       presents.            This     perspective      encourages         readers              to              be       proactive             and              to            seek             out  opportunities,          rather            than         relying          solely              on          chance             for       financial        success.\n",
            "Logprobs:             -0.01           -3.05           -0.00           -0.88           -0.00           -0.77           -1.54           -0.59           -0.00           -1.38           -0.00           -3.68           -3.22           -0.00           -0.20           -0.28           -0.00           -0.00           -0.00           -0.07           -1.56           -0.66           -0.71           -0.00           -0.25           -1.04           -0.67           -0.10           -1.12           -0.25           -1.25           -0.14           -0.01           -0.58           -1.38           -1.32           -0.41           -0.01           -0.28           -2.01           -0.60           -2.52        -9999.00           -0.03           -0.42           -0.11           -0.00           -0.18           -0.47           -0.00           -0.36           -0.24           -0.19           -0.27           -5.38           -1.29           -3.74           -0.33           -0.13           -1.24           -0.24           -0.42           -0.00           -0.81           -0.00           -0.77           -0.62           -4.26           -0.07           -1.64           -1.45            0.00           -4.29           -0.44           -0.00           -2.71           -0.24           -0.84           -0.02\n",
            "Linprob:             99.21%           4.72%         100.00%          41.43%          99.99%          46.35%          21.39%          55.48%         100.00%          25.28%         100.00%           2.53%           3.99%          99.63%          81.74%          75.60%          99.51%          99.99%         100.00%          93.45%          21.07%          51.54%          49.00%          99.98%          77.82%          35.32%          51.09%          90.15%          32.68%          77.68%          28.57%          87.30%          99.48%          55.80%          25.13%          26.83%          66.08%          98.58%          75.31%          13.40%          55.01%           8.06%           0.00%          97.40%          65.82%          89.78%          99.99%          83.46%          62.55%         100.00%          69.47%          78.45%          82.84%          76.70%           0.46%          27.59%           2.38%          71.88%          87.65%          29.04%          78.84%          65.83%          99.99%          44.65%          99.96%          46.45%          53.95%           1.42%          93.33%          19.41%          23.54%         100.00%           1.37%          64.68%         100.00%           6.66%          78.48%          43.21%          97.72%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 3.667049016723017e+31 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we combine the tokens into groups of N, where the logprobs are determined through an aggregate function like a minimum or a mean."
      ],
      "metadata": {
        "id": "FSZha1s7ujXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('aggregate by number of words: 7 \\naggregate function: min')\n",
        "logprobs_pretty_print(sequential_combine(combine_token_to_word(response), 7, min), question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOoXHGEHqrrU",
        "outputId": "4cae6d69-6862-489b-ae6b-7e58b09909b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate by number of words: 7 \n",
            "aggregate function: min\n",
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                  In \"The Richest Man in Babylon,\" Arkad,                   who is the richest man in Babylon,  believes that good luck follows opportunity because                       he sees luck as a byproduct of     one’s readiness to seize opportunities when they                                               arise.              He explains that many people often miss          chances to become wealthy because they fail           to recognize or act upon the opportunities                                presented to them. \n",
            "\n",
            "\n",
            "Logprobs:                                                  -0.57                                                -1.70                                                -0.24                                                -1.81                                                -5.79                                                -0.01                                                -1.98                                                -3.90                                                -1.71                                                -0.52\n",
            "Linprob:                                                  56.64%                                               18.24%                                               78.93%                                               16.30%                                                0.30%                                               98.58%                                               13.81%                                                2.02%                                               18.03%                                               59.75%\n",
            "======================================================================================================================================================\n",
            "Tokens:              Arkad suggests that those who are diligent,           prepared, and willing to work toward their     goals are more likely to encounter opportunities                                that lead to success.               In essence, he emphasizes that luck is              not merely random chance; rather, it is   created through effort, willingness to take risks,                 and the ability to recognize and act                       on chances that life presents.  This perspective encourages readers to be proactive           and to seek out opportunities, rather than      relying solely on chance for financial success.\n",
            "Logprobs:                                                  -3.05                                                -3.68                                                -1.56                                                -0.71                                                -1.25                                                -1.38                                             -9999.00                                                -0.47                                                -5.38                                                -1.24                                                -4.26                                                -4.29\n",
            "Linprob:                                                   4.72%                                                2.53%                                               21.07%                                               49.00%                                               28.57%                                               25.13%                                                0.00%                                               62.55%                                                0.46%                                               29.04%                                                1.42%                                                1.37%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.9276138879424624e+198 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('aggregate by number of words: 7 \\naggregate function: mean')\n",
        "logprobs_pretty_print(sequential_combine(combine_token_to_word(response), 7, np.mean), question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xsc_WzdrPYz",
        "outputId": "d552da59-a903-4e01-e18f-1b437a73f9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aggregate by number of words: 7 \n",
            "aggregate function: mean\n",
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                  In \"The Richest Man in Babylon,\" Arkad,                   who is the richest man in Babylon,  believes that good luck follows opportunity because                       he sees luck as a byproduct of     one’s readiness to seize opportunities when they                                               arise.              He explains that many people often miss          chances to become wealthy because they fail           to recognize or act upon the opportunities                                presented to them. \n",
            "\n",
            "\n",
            "Logprobs:                                                  -0.09                                                -0.49                                                -0.04                                                -0.53                                                -1.20                                                -0.01                                                -1.03                                                -1.47                                                -0.40                                                -0.33\n",
            "Linprob:                                                  91.56%                                               61.21%                                               96.54%                                               58.75%                                               29.98%                                               98.58%                                               35.58%                                               23.11%                                               67.18%                                               71.86%\n",
            "======================================================================================================================================================\n",
            "Tokens:              Arkad suggests that those who are diligent,           prepared, and willing to work toward their     goals are more likely to encounter opportunities                                that lead to success.               In essence, he emphasizes that luck is              not merely random chance; rather, it is   created through effort, willingness to take risks,                 and the ability to recognize and act                       on chances that life presents.  This perspective encourages readers to be proactive           and to seek out opportunities, rather than      relying solely on chance for financial success.\n",
            "Logprobs:                                                  -0.89                                                -1.27                                                -0.30                                                -0.41                                                -0.65                                                -0.57                                             -1429.24                                                -0.21                                                -2.20                                                -0.40                                                -1.26                                                -1.22\n",
            "Linprob:                                                  40.92%                                               28.18%                                               73.96%                                               66.58%                                               52.02%                                               56.49%                                                0.00%                                               81.34%                                               11.08%                                               66.74%                                               28.47%                                               29.53%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 3.233617770173765e+28 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! We can see that it's actually unsure with a lot of things, maybe because the llm lacks information about these things. Therefore, we can use RAG to specifically query for this."
      ],
      "metadata": {
        "id": "MODexNsPvfkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Joe Biden"
      ],
      "metadata": {
        "id": "APAJNC_rvTZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_joe_biden = 'When was joe biden born?'\n",
        "response_joe_biden = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who's an expert in famous american figures. If you dont know the person, say 'IDK'\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_joe_biden},\n",
        "      ],\n",
        "      logprobs=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "WtAoRU0hgNTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(response_joe_biden, prompt_joe_biden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcN0m97DKsdh",
        "outputId": "e3693079-79e3-4dd8-ad10-3de6e19234b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     When was joe biden born?\n",
            "Response:   Joe Biden was born on November 20, 1942. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:           Joe     Biden       was      born        on  November                  20         ,                 194         2         .\n",
            "Logprobs:        0.00      0.00      0.00      0.00      0.00     -0.00      0.00      0.00      0.00      0.00      0.00      0.00     -0.00\n",
            "Linprob:      100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.0000001764987771 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(combine_token_to_word(response_joe_biden), prompt_joe_biden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_K36-z2h2rq",
        "outputId": "07b2fdb3-050b-4399-ca8d-e02b688acff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     When was joe biden born?\n",
            "Response:   Joe Biden was born on November 20, 1942. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:           Joe     Biden       was      born        on  November       20,     1942.\n",
            "Logprobs:        0.00      0.00      0.00      0.00      0.00     -0.00      0.00     -0.00\n",
            "Linprob:      100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%   100.00%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.0000002868105287 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Unknown Person"
      ],
      "metadata": {
        "id": "gvaqH0B8OVjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_unknown_person = 'When was jake amber born?'\n",
        "response_unknown_person = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who's an expert in famous american figures. If you don't know the person, make up random innformations.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_unknown_person},\n",
        "      ],\n",
        "      logprobs=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "cIvD0WrgKDDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(response_unknown_person, prompt_unknown_person)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZSlG4yyONLn",
        "outputId": "7be9427f-3dca-4f1b-ec1e-5a5fe4b526df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     When was jake amber born?\n",
            "Response:   I'm sorry, but I don't have any information on a figure named Jake Amber. It's possible he could be a fictional character or a less-known individual. If you have any other questions about more prominent American figures or historical personalities, feel free to ask! \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                I'm          sorry              ,            but              I          don't           have            any    information             on              a         figure          named           Jake          Amber              .           It's       possible             he          could             be              a      fictional      character             or              a           less         -known     individual              .             If            you           have            any          other      questions          about           more      prominent       American        figures             or     historical  personalities              ,           feel           free             to            ask              !\n",
            "Logprobs:            -2.15          -0.00          -0.00          -0.00          -0.46          -1.64          -0.00          -0.02          -0.01          -0.17          -0.04          -0.84          -0.01          -0.00          -0.00          -0.01          -0.36          -0.00          -1.06          -2.91          -0.00          -0.01          -2.68          -0.02          -0.03          -0.16          -1.61          -1.61          -0.10          -0.00          -0.11          -0.32          -0.88          -0.55          -0.68          -1.00          -1.60          -1.68          -1.35          -0.73          -0.00          -0.35          -2.36          -0.92          -0.00          -0.03           0.00           0.00          -0.00          -0.00\n",
            "Linprob:            11.70%         99.64%        100.00%        100.00%         63.28%         19.48%         99.98%         97.66%         99.37%         84.31%         95.81%         42.99%         99.14%        100.00%        100.00%         99.15%         69.86%        100.00%         34.65%          5.46%         99.98%         99.26%          6.84%         98.14%         97.07%         85.19%         19.92%         19.90%         90.19%         99.87%         89.64%         72.83%         41.64%         57.75%         50.51%         36.72%         20.15%         18.65%         26.02%         48.04%         99.94%         70.58%          9.42%         40.05%        100.00%         97.09%        100.00%        100.00%        100.00%         99.94%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.7668376937014785 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(combine_token_to_word(response_unknown_person), prompt_unknown_person)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qaz_OG0O2kt",
        "outputId": "6f45f8ac-0923-4a1a-98a7-033e0ac912d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     When was jake amber born?\n",
            "Response:   I'm sorry, but I don't have any information on a figure named Jake Amber. It's possible he could be a fictional character or a less-known individual. If you have any other questions about more prominent American figures or historical personalities, feel free to ask! \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                 I'm          sorry,             but               I           don't            have             any     information              on               a          figure           named            Jake          Amber.            It's        possible              he           could              be               a       fictional       character              or               a      less-known     individual.              If             you            have             any           other       questions           about            more       prominent        American         figures              or      historical  personalities,            feel            free              to            ask!\n",
            "Logprobs:             -2.15           -0.00           -0.00           -0.46           -1.64           -0.00           -0.02           -0.01           -0.17           -0.04           -0.84           -0.01           -0.00           -0.01           -0.36           -0.00           -1.06           -2.91           -0.00           -0.01           -2.68           -0.02           -0.03           -0.16           -1.61           -0.10           -0.11           -0.32           -0.88           -0.55           -0.68           -1.00           -1.60           -1.68           -1.35           -0.73           -0.00           -0.35           -2.36           -0.92           -0.03            0.00            0.00           -0.00\n",
            "Linprob:             11.70%          99.64%         100.00%          63.28%          19.48%          99.98%          97.66%          99.37%          84.31%          95.81%          42.99%          99.14%         100.00%          99.15%          69.86%         100.00%          34.65%           5.46%          99.98%          99.26%           6.84%          98.14%          97.07%          85.19%          19.90%          90.19%          89.64%          72.83%          41.64%          57.75%          50.51%          36.72%          20.15%          18.65%          26.02%          48.04%          99.94%          70.58%           9.42%          40.05%          97.09%         100.00%         100.00%          99.94%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.8406374396789553 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(sequential_combine(combine_token_to_word(response_unknown_person), 4, np.mean), prompt_unknown_person)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GazOtbEWP4kp",
        "outputId": "4ec83f95-a8c1-44d8-b737-9b32edd53255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     When was jake amber born?\n",
            "Response:   I'm sorry, but I don't have any information on a figure named Jake Amber. It's possible he could be a fictional character or a less-known individual. If you have any other questions about more prominent American figures or historical personalities, feel free to ask! \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                         I'm sorry, but I           don't have any information                    on a figure named                          Jake Amber.               It's possible he could             be a fictional character          or a less-known individual.                      If you have any           other questions about more        prominent American figures or  historical personalities, feel free                              to ask!\n",
            "Logprobs:                                  -0.65                                -0.42                                -0.27                                -0.00                                -1.08                                -0.68                                -0.48                                -0.46                                -1.24                                -0.61                                -0.83                                -0.00\n",
            "Linprob:                                  52.12%                               65.94%                               76.60%                               99.57%                               33.90%                               50.80%                               62.07%                               62.94%                               28.90%                               54.49%                               43.74%                               99.97%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.7497282262535274 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that it's very unsure with a lot of things when it makes thigns up"
      ],
      "metadata": {
        "id": "ArCIE_9hvcr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 2. Annotating\n"
      ],
      "metadata": {
        "id": "S3RQEDgHwFme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def annotater(response, tolerance=-0.4):\n",
        "    \"\"\"\n",
        "    Given an OpenAI response object with logprobs, marks all the tokens\n",
        "    where the logprob is below the tolerance as uncertain by adding a field\n",
        "    called uncertain and marking it as True.\n",
        "\n",
        "    Args:\n",
        "        response: OpenAI response object\n",
        "        tolerance: int\n",
        "\n",
        "    Returns:\n",
        "        An OpenAI response object\n",
        "    \"\"\"\n",
        "    temp_response = copy.deepcopy(response)\n",
        "    for token_data in temp_response.choices[0].logprobs.content:\n",
        "        if token_data.logprob < tolerance:\n",
        "            token_data.uncertain = True\n",
        "        else:\n",
        "            token_data.uncertain = False\n",
        "    return temp_response\n",
        "\n",
        "\n",
        "def annotated_combiner(response, aggregate_func=np.mean):\n",
        "    \"\"\"\n",
        "    Given a OpenAI response object with logprobs, combines all adjacent\n",
        "    token data objects in the list of response into one token data object,\n",
        "    aggregated with aggregate_func.\n",
        "\n",
        "    Args:\n",
        "        response: OpenAI Response object\n",
        "        aggregate_func: a function that accepts n-numbers of int as it's argument and returns an int\n",
        "\n",
        "    Returns:\n",
        "        An OpenAI response object\n",
        "    \"\"\"\n",
        "    temp_response = copy.deepcopy(response)\n",
        "    index_groups = []\n",
        "    current_group = []\n",
        "    for token_data in temp_response.choices[0].logprobs.content:\n",
        "        if token_data.uncertain:\n",
        "            if ('\\n' not in token_data.token) and ('.' not in token_data.token) and ('?' not in token_data.token) and ('!' not in token_data.token):\n",
        "                current_group += [token_data]\n",
        "            else:\n",
        "                if len(current_group) > 0:\n",
        "                    index_groups += [current_group]\n",
        "                    current_group = []\n",
        "                index_groups += [[token_data]]\n",
        "        else:\n",
        "            if len(current_group) > 0:\n",
        "                index_groups += [current_group]\n",
        "                current_group = []\n",
        "                index_groups += [[token_data]]\n",
        "                continue\n",
        "            index_groups += [[token_data]]\n",
        "    log_probs_list = []\n",
        "    for group in index_groups:\n",
        "        log_probs_list += [token_data_group_sequeeze(group, aggregate_func)]\n",
        "    temp_response.choices[0].logprobs.content = log_probs_list\n",
        "    return temp_response\n",
        "\n",
        "\n",
        "def uncertain_marker(response):\n",
        "    \"\"\"\n",
        "    Given an OpenAI response object with logprobs, modifies all the logprobs token data list\n",
        "    strings where uncertain is set to True with '[uncertain]' + token + '[/uncertain]'.\n",
        "\n",
        "    Args:\n",
        "        response: OpenAI Object\n",
        "\n",
        "    Returns:\n",
        "        An OpenAI response object\n",
        "    \"\"\"\n",
        "    temp_response = copy.deepcopy(response)\n",
        "    if not hasattr(response.choices[0].logprobs.content[0], 'uncertain'):\n",
        "        temp_response = annotated_combiner(annotater(temp_response))\n",
        "    for token_data in temp_response.choices[0].logprobs.content:\n",
        "        if token_data.uncertain:\n",
        "            token_data.token = ' ([uncertain]' + \\\n",
        "                token_data.token + ' [/uncertain]) '\n",
        "    temp_response.choices[0].message.content = ''.join(\n",
        "        [i.token for i in temp_response.choices[0].logprobs.content])\n",
        "    return temp_response"
      ],
      "metadata": {
        "id": "aDVpAABLwRu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_pretty_print(sequential_combine(combine_token_to_word(response), 5, np.mean), question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyOglhNRva39",
        "outputId": "a07634e3-1d36-4c70-d6f4-b1686807ca1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                      In \"The Richest Man in             Babylon,\" Arkad, who is the        richest man in Babylon, believes      that good luck follows opportunity                 because he sees luck as          a byproduct of one’s readiness        to seize opportunities when they                                  arise.            He explains that many people            often miss chances to become            wealthy because they fail to               recognize or act upon the     opportunities presented to them. \n",
            "\n",
            "\n",
            "Logprobs:                                     -0.01                                   -0.57                                   -0.28                                   -0.00                                   -0.33                                   -1.92                                   -0.18                                   -0.01                                   -0.69                                   -2.25                                   -0.55                                   -0.56                                   -0.25\n",
            "Linprob:                                     99.03%                                  56.80%                                  75.39%                                  99.94%                                  71.66%                                  14.69%                                  83.39%                                  98.58%                                  50.08%                                  10.50%                                  57.55%                                  57.39%                                  77.90%\n",
            "======================================================================================================================================================\n",
            "Tokens:               Arkad suggests that those who     are diligent, prepared, and willing              to work toward their goals            are more likely to encounter     opportunities that lead to success.          In essence, he emphasizes that               luck is not merely random           chance; rather, it is created     through effort, willingness to take               risks, and the ability to            recognize and act on chances                     that life presents.  This perspective encourages readers to                be proactive and to seek  out opportunities, rather than relying          solely on chance for financial                                success.\n",
            "Logprobs:                                     -0.79                                   -0.86                                   -1.42                                   -0.07                                   -0.64                                   -0.64                                   -0.67                                   -0.81                                -2000.51                                   -0.15                                   -1.29                                   -1.79                                   -0.40                                   -1.29                                   -1.49                                   -0.85                                   -0.02\n",
            "Linprob:                                     45.45%                                  42.52%                                  24.16%                                  93.19%                                  52.89%                                  52.87%                                  51.08%                                  44.59%                                   0.00%                                  85.93%                                  27.60%                                  16.77%                                  66.71%                                  27.55%                                  22.57%                                  42.95%                                  97.72%\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.824301272459658e+29 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's for all the tokens(sequence of tokens) where the logprobs is below -0.4, we mark them as uncertain and add them as a field"
      ],
      "metadata": {
        "id": "ZLi3BA6Ol3RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_rmib = annotater(sequential_combine(combine_token_to_word(response), 5, np.mean), tolerance= -0.4)\n",
        "logprobs_pretty_print(annotated_rmib, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzdJAA2cwyn2",
        "outputId": "8b282535-60e7-48e3-a833-30fb1ad8dfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                      In \"The Richest Man in             Babylon,\" Arkad, who is the        richest man in Babylon, believes      that good luck follows opportunity                 because he sees luck as          a byproduct of one’s readiness        to seize opportunities when they                                  arise.            He explains that many people            often miss chances to become            wealthy because they fail to               recognize or act upon the     opportunities presented to them. \n",
            "\n",
            "\n",
            "Logprobs:                                     -0.01                                   -0.57                                   -0.28                                   -0.00                                   -0.33                                   -1.92                                   -0.18                                   -0.01                                   -0.69                                   -2.25                                   -0.55                                   -0.56                                   -0.25\n",
            "Linprob:                                     99.03%                                  56.80%                                  75.39%                                  99.94%                                  71.66%                                  14.69%                                  83.39%                                  98.58%                                  50.08%                                  10.50%                                  57.55%                                  57.39%                                  77.90%\n",
            "Uncertainty:                                   False                                    True                                   False                                   False                                   False                                    True                                   False                                   False                                    True                                    True                                    True                                    True                                   False\n",
            "======================================================================================================================================================\n",
            "Tokens:               Arkad suggests that those who     are diligent, prepared, and willing              to work toward their goals            are more likely to encounter     opportunities that lead to success.          In essence, he emphasizes that               luck is not merely random           chance; rather, it is created     through effort, willingness to take               risks, and the ability to            recognize and act on chances                     that life presents.  This perspective encourages readers to                be proactive and to seek  out opportunities, rather than relying          solely on chance for financial                                success.\n",
            "Logprobs:                                     -0.79                                   -0.86                                   -1.42                                   -0.07                                   -0.64                                   -0.64                                   -0.67                                   -0.81                                -2000.51                                   -0.15                                   -1.29                                   -1.79                                   -0.40                                   -1.29                                   -1.49                                   -0.85                                   -0.02\n",
            "Linprob:                                     45.45%                                  42.52%                                  24.16%                                  93.19%                                  52.89%                                  52.87%                                  51.08%                                  44.59%                                   0.00%                                  85.93%                                  27.60%                                  16.77%                                  66.71%                                  27.55%                                  22.57%                                  42.95%                                  97.72%\n",
            "Uncertainty:                                    True                                    True                                    True                                   False                                    True                                    True                                    True                                    True                                    True                                   False                                    True                                    True                                    True                                    True                                    True                                    True                                   False\n",
            "======================================================================================================================================================\n",
            "Perplexity: 1.824301272459658e+29 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there a lot of adjacent sequences of tokens where the LLM is uncertain, it would make sense to combine them into one sequence of tokens and aggregate the logprob with an aggregate function."
      ],
      "metadata": {
        "id": "xiN5rAwBmPfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_combined = annotated_combiner(annotated_rmib, np.mean)\n",
        "logprobs_pretty_print(annotated_combined, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifD7QsmU0OQr",
        "outputId": "b7dd0d82-13a7-4a8a-c35d-54664a67aef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:     Why did Arkad believe that good luck follows opportunity?\n",
            "Response:   In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. \n",
            "\n",
            "======================================================================================================================================================\n",
            "Tokens:                                                                                                                     In \"The Richest Man in                                                                                                            Babylon,\" Arkad, who is the                                                                                                       richest man in Babylon, believes                                                                                                     that good luck follows opportunity                                                                                                                because he sees luck as                                                                                                         a byproduct of one’s readiness                                                                                                       to seize opportunities when they                                                                                                                                 arise.                       He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the                                                                                                    opportunities presented to them. \n",
            "\n",
            "\n",
            "Logprobs:                                                                                                                                    -0.01                                                                                                                                  -0.57                                                                                                                                  -0.28                                                                                                                                  -0.00                                                                                                                                  -0.33                                                                                                                                  -1.92                                                                                                                                  -0.18                                                                                                                                  -0.01                                                                                                                                  -1.01                                                                                                                                  -0.25\n",
            "Linprob:                                                                                                                                    99.03%                                                                                                                                 56.80%                                                                                                                                 75.39%                                                                                                                                 99.94%                                                                                                                                 71.66%                                                                                                                                 14.69%                                                                                                                                 83.39%                                                                                                                                 98.58%                                                                                                                                 36.30%                                                                                                                                 77.90%\n",
            "Uncertainty:                                                                                                                                  False                                                                                                                                   True                                                                                                                                  False                                                                                                                                  False                                                                                                                                  False                                                                                                                                   True                                                                                                                                  False                                                                                                                                  False                                                                                                                                   True                                                                                                                                  False\n",
            "======================================================================================================================================================\n",
            "Tokens:                                               Arkad suggests that those who are diligent, prepared, and willing to work toward their goals                                                                                                           are more likely to encounter                                                                                                    opportunities that lead to success.             In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take                                                                                                              risks, and the ability to                                                                                                           recognize and act on chances                                                                                                                    that life presents.  This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial                                                                                                                               success.\n",
            "Logprobs:                                                                                                                                    -1.02                                                                                                                                  -0.07                                                                                                                                  -0.64                                                                                                                                -500.66                                                                                                                                  -0.15                                                                                                                                  -1.29                                                                                                                                  -1.79                                                                                                                                  -1.01                                                                                                                                  -0.02\n",
            "Linprob:                                                                                                                                    36.01%                                                                                                                                 93.19%                                                                                                                                 52.89%                                                                                                                                  0.00%                                                                                                                                 85.93%                                                                                                                                 27.60%                                                                                                                                 16.77%                                                                                                                                 36.53%                                                                                                                                 97.72%\n",
            "Uncertainty:                                                                                                                                   True                                                                                                                                  False                                                                                                                                   True                                                                                                                                   True                                                                                                                                  False                                                                                                                                   True                                                                                                                                   True                                                                                                                                   True                                                                                                                                  False\n",
            "======================================================================================================================================================\n",
            "Perplexity: 484203421402.9794 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's combine all the tokens into a single string and mark the uncertain ones with [uncertain] [/uncertain]"
      ],
      "metadata": {
        "id": "MvBmLGyfmlBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxad6lPV0lU3",
        "outputId": "44dd1460-f36c-4e72-999c-f4460881bb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he sees luck as a byproduct of one’s readiness to seize opportunities when they arise. He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the opportunities presented to them. \n",
            "\n",
            "Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter opportunities that lead to success. In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on chances that life presents. This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "marked_response = uncertain_marker(annotated_combined)\n",
        "print(marked_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ee0k5by6r1",
        "outputId": "3ebf0c19-a5ac-4cdf-811f-ecf65192e0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In \"The Richest Man in ([uncertain] Babylon,\" Arkad, who is the [/uncertain])  richest man in Babylon, believes that good luck follows opportunity because he sees luck as ([uncertain] a byproduct of one’s readiness [/uncertain])  to seize opportunities when they arise. ([uncertain] He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the [/uncertain])  opportunities presented to them. \n",
            "\n",
            " ([uncertain]Arkad suggests that those who are diligent, prepared, and willing to work toward their goals [/uncertain])  are more likely to encounter ([uncertain] opportunities that lead to success. [/uncertain])  ([uncertain] In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take [/uncertain])  risks, and the ability to ([uncertain] recognize and act on chances [/uncertain])  ([uncertain] that life presents. [/uncertain])  ([uncertain] This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial [/uncertain])  success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Constructing questions to get a more confident answer for that token."
      ],
      "metadata": {
        "id": "MMMbBvMXzdqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first we need to replace the uncertain tokens with the question."
      ],
      "metadata": {
        "id": "1Jie1gpquDFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marked_response_question_replaced = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a book expert that answers questions about books. \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "        {\"role\": \"assistant\", \"content\": response.choices[0].message.content},\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"The answer has been marked to where you are uncertain with the phrases. For every, phrases in between\n",
        "        [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)]\n",
        "\n",
        "        First example:\n",
        "        user: What is meaning of the colors in the flag of Ghana?\n",
        "        assistant: Red is for the blood of martyrs, green for forests, and gold for mineral wealth.\n",
        "        user: Here's the annotated version: ([uncertain] Red [/uncertain]) is for the blood of martyrs, ([uncertain] green for forests [/uncertain]), and gold for mineral wealth.\n",
        "        assistant: [Search(is red a color in the flag of Ghana?)] is for the blood of martyrs, [Search(is green a color in the flag of Ghana? If so, what does it symbolize?)], and gold for mineral wealth.\n",
        "\n",
        "        Second example:\n",
        "        user: Give me a very short summary of Joe Biden's journey becoming the president!\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on August 18, 2019. His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        user: Here's an annotated version: Joe Biden announced his candidacy for the 2020 presidential election on ([uncertain] August 18, 2019 [/uncertain]). His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on [Search(When did Joe Biden announce his candidancy for the 2020 presidential election?)].  His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Here's the annotated version: {marked_response.choices[0].message.content}\"},\n",
        "      ],\n",
        "      logprobs=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "EgthTGbGnKOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(marked_response_question_replaced.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oz20yUstirl",
        "outputId": "947d061c-5597-4a07-9e98-450158f498bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In \"The Richest Man in [Search(What is the setting of the book \"The Richest Man in Babylon\"?)], Arkad, who is the [Search(Who is Arkad in the context of the book?)] richest man in Babylon, believes that good luck follows opportunity because he sees luck as [Search(What does Arkad mean by \"a byproduct of one’s readiness\" in terms of seizing opportunities?)] to seize opportunities when they arise. [Search(Why do people miss chances to become wealthy according to Arkad?)] He explains that many people often miss chances to become wealthy because they fail to recognize or act upon the [Search(What type of opportunities does Arkad refer to in the book?)] opportunities presented to them.\n",
            "\n",
            "[Search(What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?)] Arkad suggests that those who are diligent, prepared, and willing to work toward their goals are more likely to encounter [Search(What are examples of opportunities that lead to success in the book?)] opportunities that lead to success. [Search(What does Arkad say about the nature of luck?)] In essence, he emphasizes that luck is not merely random chance; rather, it is created through effort, willingness to take [Search(What type of risks does Arkad encourage people to take?)] risks, and the ability to [Search(How does one recognize and act on chances?)][Search(What does Arkad mean by \"chances\" in the context of life?)] recognize and act on chances [Search(What does Arkad mean by \"that life presents\"?)] that life presents. [Search(Why does Arkad advocate for a proactive approach to achieving financial success?)] This perspective encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial [Search(What does financial success mean in the context of the book?)] success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we extract those questions into a dictionary, so we can answer each of them individually with RAG"
      ],
      "metadata": {
        "id": "7wJWnys-uV0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_extracted = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a book expert that answers questions about books. \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "        {\"role\": \"assistant\", \"content\": response.choices[0].message.content},\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"The answer has been marked to where you are uncertain with the phrases. For every, phrases in between\n",
        "        [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)]\n",
        "\n",
        "        First example:\n",
        "        user: What is meaning of the colors in the flag of Ghana?\n",
        "        assistant: Red is for the blood of martyrs, green for forests, and gold for mineral wealth.\n",
        "        user: Here's the annotated version: ([uncertain] Red [/uncertain]) is for the blood of martyrs, ([uncertain] green for forests [/uncertain]), and gold for mineral wealth.\n",
        "        assistant: [Search(is red a color in the flag of Ghana?)] is for the blood of martyrs, [Search(is green a color in the flag of Ghana? If so, what does it symbolize?)], and gold for mineral wealth.\n",
        "\n",
        "        Second example:\n",
        "        user: Give me a very short summary of Joe Biden's journey becoming the president!\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on August 18, 2019. His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        user: Here's an annotated version: Joe Biden announced his candidacy for the 2020 presidential election on ([uncertain] August 18, 2019 [/uncertain]). His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on [Search(When did Joe Biden announce his candidancy for the 2020 presidential election?)].  His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Here's the annotated version: {marked_response.choices[0].message.content}\"},\n",
        "        {\"role\": \"assistant\", \"content\": marked_response_question_replaced.choices[0].message.content},\n",
        "        {'role': \"user\", \"content\": \"\"\"Now for all the questions marked as [Search(question)], please extract them in a python dictionary format:\n",
        "        {\n",
        "          \"1\": \"question 1\",\n",
        "          \"2\": \"question 2\",\n",
        "          ...\n",
        "          \"n\": \"question n\"\n",
        "        }\n",
        "        it is critical to only output the dictionary and nothing else.\n",
        "        \"\"\"}\n",
        "      ],\n",
        "    )"
      ],
      "metadata": {
        "id": "GaL_txjEt4hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_extracted.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj0SVuU_uB8x",
        "outputId": "8c2d0e87-93c7-4c17-9bee-185048564e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"1\": \"What is the setting of the book 'The Richest Man in Babylon'?\",\n",
            "  \"2\": \"Who is Arkad in the context of the book?\",\n",
            "  \"3\": \"What does Arkad mean by 'a byproduct of one’s readiness' in terms of seizing opportunities?\",\n",
            "  \"4\": \"Why do people miss chances to become wealthy according to Arkad?\",\n",
            "  \"5\": \"What type of opportunities does Arkad refer to in the book?\",\n",
            "  \"6\": \"What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?\",\n",
            "  \"7\": \"What are examples of opportunities that lead to success in the book?\",\n",
            "  \"8\": \"What does Arkad say about the nature of luck?\",\n",
            "  \"9\": \"What type of risks does Arkad encourage people to take?\",\n",
            "  \"10\": \"How does one recognize and act on chances?\",\n",
            "  \"11\": \"What does Arkad mean by 'chances' in the context of life?\",\n",
            "  \"12\": \"What does Arkad mean by 'that life presents'?\",\n",
            "  \"13\": \"Why does Arkad advocate for a proactive approach to achieving financial success?\",\n",
            "  \"14\": \"What does financial success mean in the context of the book?\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_dict = ast.literal_eval(question_extracted.choices[0].message.content)\n",
        "questions_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nerepIgCuxR4",
        "outputId": "521ca2ca-198f-469a-b5ad-86b002b4b65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': \"What is the setting of the book 'The Richest Man in Babylon'?\",\n",
              " '2': 'Who is Arkad in the context of the book?',\n",
              " '3': \"What does Arkad mean by 'a byproduct of one’s readiness' in terms of seizing opportunities?\",\n",
              " '4': 'Why do people miss chances to become wealthy according to Arkad?',\n",
              " '5': 'What type of opportunities does Arkad refer to in the book?',\n",
              " '6': 'What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?',\n",
              " '7': 'What are examples of opportunities that lead to success in the book?',\n",
              " '8': 'What does Arkad say about the nature of luck?',\n",
              " '9': 'What type of risks does Arkad encourage people to take?',\n",
              " '10': 'How does one recognize and act on chances?',\n",
              " '11': \"What does Arkad mean by 'chances' in the context of life?\",\n",
              " '12': \"What does Arkad mean by 'that life presents'?\",\n",
              " '13': 'Why does Arkad advocate for a proactive approach to achieving financial success?',\n",
              " '14': 'What does financial success mean in the context of the book?'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Answering These Questions"
      ],
      "metadata": {
        "id": "-eIxnA5bvcLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a retriever to answer these questions\n",
        "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\",\"\\n\", \" \"],\n",
        "    chunk_size = 1200,\n",
        "    chunk_overlap = 100,\n",
        "    # length_function = len,\n",
        "    is_separator_regex=False\n",
        ")\n",
        "\n",
        "splits = []\n",
        "for i in range(len(df_metadata)):\n",
        "  if df_metadata.loc[df_metadata.index[i]].type == 'full text':\n",
        "    continue\n",
        "  temp_splits = recursive_text_splitter.create_documents(texts=[df_metadata.loc[df_metadata.index[i]].text])\n",
        "  for temp_split in temp_splits:\n",
        "    temp_split.page_content = f'chapter: {df_metadata.loc[df_metadata.index[i]].title}\\ntype: {df_metadata.loc[df_metadata.index[i]].type}\\n\\n' + temp_split.page_content\n",
        "    splits.append(temp_split)\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"rmib\",\n",
        "    embedding_function=embeddings,\n",
        ")\n",
        "vector_store.add_documents(documents=splits, ids=[f'id_{i}' for i in range(1, len(splits) + 1)]);\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 8})"
      ],
      "metadata": {
        "id": "dvAJngBXxSuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"You are a book expert that answers questions about books.\n",
        "      Question: {question}\n",
        "      Context: called the RAG\n",
        "      Original Answer: {response.choices[0].message.content}\n",
        "\n",
        "      Now, I have marked the answer to where you are uncertain with the phrases. For every, phrases in between\n",
        "      [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)]\n",
        "\n",
        "      Annotated Answer: {marked_response.choices[0].message.content}\n",
        "      Constructed Questions Answer: {marked_response_question_replaced.choices[0].message.content}\n",
        "      \"\"\"},\n",
        "    ]"
      ],
      "metadata": {
        "id": "IHnWm43zvr77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constructed_question_answer = {}\n",
        "for i in range(1, len(questions_dict) + 1):\n",
        "    question_temp = questions_dict[str(i)]\n",
        "\n",
        "    # getting the context for the question\n",
        "    context = retriever.get_relevant_documents(question_temp)\n",
        "\n",
        "    # constructing the question and context message\n",
        "    question_string = f\"\"\"Use the following pieces of retrieved context to answer the question.\n",
        "    Question: {question}\n",
        "    Context: {format_docs(context)}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    question_message = message + [{\"role\": \"user\", \"content\": question_string}]\n",
        "\n",
        "    # answering the question\n",
        "    question_answer = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=question_message,\n",
        "    )\n",
        "    constructed_question_answer[str(i)] = [\n",
        "        question_temp, question_answer.choices[0].message.content]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itO4FsR6w76s",
        "outputId": "ca99fc42-a1fd-4714-df4e-325b704f1d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-e92dba8e0836>:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
            "  context = retriever.get_relevant_documents(question_temp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Reconstructing the Answer"
      ],
      "metadata": {
        "id": "MDmB_KQQxvcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer = \"\"\n",
        "for i in range(1, len(questions_dict) + 1):\n",
        "    question_answer += f\"\"\"Question: {questions_dict[str(i)]}\\nAnswer: {constructed_question_answer[str(i)][1]}\\n\"\"\"\n",
        "print(question_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8nEWqZfxyo9",
        "outputId": "b49e96a1-2950-4c99-9396-102ce988503c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the setting of the book 'The Richest Man in Babylon'?\n",
            "Answer: Arkad believed that good luck follows opportunity because he understood that wealth is not simply a matter of fate or luck; it is a result of taking action when opportunities present themselves. During his journey to accumulate wealth, he realized that many people fail to recognize the opportunities available to them or choose not to act on them. Instead of waiting for fortune to smile upon them, Arkad emphasized the importance of being proactive, diligent, and prepared to seize chances when they arise. \n",
            "\n",
            "According to Arkad, those who actively seek opportunities, educate themselves about how to manage and grow their wealth, and are willing to work and invest wisely are more likely to create their own \"luck.\" This philosophy is encapsulated in his advice that a part of all one earns should be kept for oneself, which reflects the notion that individuals have the power to influence their financial destiny by being open to opportunity and ready to take positive steps toward wealth accumulation.\n",
            "Question: Who is Arkad in the context of the book?\n",
            "Answer: Arkad believed that good luck follows opportunity because he understood that those who are prepared and willing to act upon the opportunities that life presents are more likely to find success. Essentially, luck, in Arkad's view, is not a mere coincidence; instead, it is a result of one’s readiness to seize chances and make the most of them. He recognized that many people fail to achieve wealth because they do not identify or take action on the opportunities available to them.\n",
            "\n",
            "Moreover, Arkad’s own experiences shaped this philosophy. He started his own fortune in humble beginnings and learned valuable lessons that he later shared with others in Babylon. His teachings emphasized that by being proactive, recognizing potential opportunities, and being willing to take calculated risks, individuals could attract what they perceive as \"good luck.\" Thus, in Arkad's perspective, the consistent effort towards preparation and action creates the conditions for good luck to manifest.\n",
            "Question: What does Arkad mean by 'a byproduct of one’s readiness' in terms of seizing opportunities?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that throughout his life, many people were presented with chances to succeed, but only those who actively seized these opportunities were able to achieve their desires. In a discussion, he explained that good luck is often a result of recognizing and acting upon opportunities as they arise, rather than something that happens without effort.\n",
            "\n",
            "Arkad emphasized that the majority of people hesitate and miss their chances, while those who are proactive and willing to work towards their goals can attract good luck into their lives. He stated, \"Good luck, we do find, often follows opportunity but seldom comes otherwise.\" Thus, he concluded that by embracing opportunities and taking action, individuals can entice good luck to come to them, as illustrated by the tales discussed among the friends. The overarching message conveys that men of action are favored by good luck, reinforcing the importance of preparedness and initiative in achieving success.\n",
            "Question: Why do people miss chances to become wealthy according to Arkad?\n",
            "Answer: Arkad believed that good luck follows opportunity because he understood that luck is often a reflection of one’s actions and readiness to seize chances when they arise. In his discussions with others, he emphasized that the notion of 'Fickle Fate' is misleading; it tends to benefit those who take unearned wealth for granted, leading to mismanagement and discontent. Instead, Arkad highlights the importance of learning and applying the principles of wealth building, indicating that opportunities for success are available to all, but only some successfully grasp them.\n",
            "\n",
            "Through his observations over the years, Arkad saw that while opportunities frequently come to individuals, many hesitate and fall behind. This gap often results in missed chances that could have led to prosperity. He further learned from the conversations with his friends that one cannot simply wait for good luck to arrive; rather, one must take proactive steps to attract it by recognizing and utilizing opportunities.\n",
            "\n",
            "Arkad's belief is reinforced by the idea that wealth is not just created in isolation; it multiplies as individuals exert effort and engage with available opportunities. He conveys that those who are industrious and prepared will naturally encounter favorable circumstances, thus bridging the connection between good luck and the willingness to act on opportunities.\n",
            "Question: What type of opportunities does Arkad refer to in the book?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed throughout his life that success comes to those who are prepared to seize the opportunities that present themselves. He noted that while many individuals encountered opportunities, only a few grasped them and achieved their desires, while the majority hesitated or faltered and consequently fell behind. \n",
            "\n",
            "From the discussions in the temple, it became clear to Arkad and others that good luck is not simply a matter of chance or something that might happen without effort. Instead, to attract good luck, one must take action and make the most of the opportunities that arise. This understanding led to a broader perspective on how individuals can actively seek out and capitalize on their chances for success, emphasizing that preparing for and recognizing opportunities is essential for financial achievement and personal growth. \n",
            "\n",
            "In summary, Arkad highlighted that effort and recognition of opportunities are crucial in transforming luck from a mere chance event into a consistent part of one's journey toward success.\n",
            "Question: What characteristics do diligent, prepared, and hardworking people exhibit according to Arkad?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed throughout his life that while opportunities are available to everyone, not all individuals take advantage of them. He noted a pattern where some men successfully seized their opportunities and achieved their deepest desires, while the majority hesitated or faltered, ultimately falling behind. His perspective suggests that good luck is not a random occurrence but rather a result of one's readiness and willingness to act when opportunities arise. He emphasized the importance of making the most of these opportunities to attract good luck to oneself, advocating for a proactive approach to achieving success rather than waiting passively for fortune to favor them.\n",
            "Question: What are examples of opportunities that lead to success in the book?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that throughout his life, successful individuals were those who actively seized opportunities as they arose. In his discussions, he noted that while opportunities were available to all, many people hesitated and missed their chances, ultimately falling behind. He emphasized that good luck is often associated with taking action—seizing opportunities and being proactive—rather than waiting for luck to come without effort. Arkad illustrated this belief by sharing that good fortune often aligns with those who are eager to improve their circumstances by accepting available opportunities.\n",
            "\n",
            "He also pointed out that good luck seldom comes to those who do not recognize or act on the opportunities before them. This perspective suggests that being prepared to take action and being willing to work toward one's goals attracts the 'interest of the goddess of good luck.' In essence, Arkad's insights underline the relationship between good luck and action taken toward recognizing and capitalizing on opportunities for success.\n",
            "Question: What does Arkad say about the nature of luck?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that throughout his life, those who achieved success were the ones who seized the opportunities presented to them. He noted that while opportunities were available to many, a significant portion of people hesitated or faltered, ultimately falling behind. Arkad argued that to attract good luck, one must be proactive and take advantage of the chances that arise. He highlights discussions in which others began to see good luck as something that is not merely a spontaneous occurrence, but rather something that can be cultivated through effort and action towards recognizing and acting upon opportunities. This understanding reinforced Arkad's belief that good luck is closely linked to the willingness to engage with life's opportunities.\n",
            "Question: What type of risks does Arkad encourage people to take?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that those who seize opportunities tend to achieve their deepest desires, whereas those who hesitate or fail to act often miss out on potential successes. In his discussions, Arkad emphasized the need for individuals to actively recognize and take advantage of opportunities in order to attract good luck into their lives. He argued that luck is not simply a matter of chance but is instead created through one’s readiness and willingness to engage with the chances that arise. Arkad's insights suggest that diligent effort and a proactive attitude play significant roles in transforming opportunities into successful outcomes. This belief was reinforced during his interactions with others in Babylon, where he advised them on investing wisely and encouraged them to learn how to become wealthy by understanding and acting upon opportunities as they presented themselves. Overall, Arkad conveyed that good luck is a result of one’s actions and decisions rather than mere happenstance.\n",
            "Question: How does one recognize and act on chances?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed throughout his life that many individuals encountered opportunities but only a few acted on them. He noted that those who were proactive and willing to seize opportunities were able to achieve their goals and desires, while the majority who hesitated, faltered, or fell behind missed out on their chances for success. \n",
            "\n",
            "In discussions with others, Arkad emphasized that good luck is not merely a stroke of fortune that comes to those who wait passively; rather, it is a result of taking action and accepting opportunities when they arise. He highlighted that to attract good luck, one must actively engage with opportunities and work to make the most of them. The idea is that by being a \"man of action,\" individuals can draw the attention of good luck, symbolized by the good goddess, who favors those who are eager to improve their circumstances. Thus, Arkad’s philosophy is that good luck is closely tied to the readiness and willingness to take action when opportunities present themselves.\n",
            "Question: What does Arkad mean by 'chances' in the context of life?\n",
            "Answer: Arkad believed that good luck follows opportunity because, through his long life experiences, he observed that success is a result of recognizing and acting upon opportunities that arise. In his discussions, he noted that although many people encounter opportunities, only a few take the initiative to seize them. The majority tend to hesitate or falter, which leads to them missing out on their chances for success. \n",
            "\n",
            "Moreover, one of the characters in the conversation acknowledges a shift in understanding about good luck, realizing that it isn't something that happens without effort but rather is attracted through the proactive engagement with opportunities. Arkad reinforces this perspective by emphasizing that to attract good luck, one must take advantage of the opportunities presented, which implies an active pursuit rather than a passive waiting for fortune to bestow itself upon someone.\n",
            "\n",
            "Ultimately, Arkad's belief reflects a philosophy that luck is not merely random chance, but a consequence of one's preparedness and willingness to act when the right circumstances arise. Therefore, by being proactive and diligent in seeking opportunities, an individual can create their own luck.\n",
            "Question: What does Arkad mean by 'that life presents'?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that, throughout his life, certain individuals consistently seized the opportunities presented to them, leading to their success and the fulfillment of their desires. In his discussions, he highlighted that these opportunities were available to everyone; however, the majority of people hesitated or faltered, which caused them to fall behind.\n",
            "\n",
            "He emphasized that good luck is not a random occurrence but rather a result of one's actions and readiness to take advantage of opportunities. During his conversations with others, Arkad pointed out that to attract good luck, one must actively engage with the possibilities that arise in their lives. This necessary engagement involves recognizing and acting on opportunities, as opposed to waiting passively for good fortune to strike. \n",
            "\n",
            "Moreover, Arkad's reflections indicate that he viewed luck as something that can be cultivated through effort and persistence in one's endeavors, rather than a mere stroke of chance. Essentially, he proposed that by being industrious, diligent, and proactive, individuals can increase their chances of encountering opportunities that lead to success, thus attracting good luck to themselves.\n",
            "Question: Why does Arkad advocate for a proactive approach to achieving financial success?\n",
            "Answer: Arkad believed that good luck follows opportunity because he observed that many individuals fail to seize the chances presented to them due to hesitation and indecision. In the discussions he had with his students, he emphasized the importance of being prepared and ready to take action when opportunities arise. \n",
            "\n",
            "He explained that good luck is not simply a random occurrence; rather, it is something that can be attracted by recognizing and capitalizing on opportunities. As Arkad stated, “to attract good luck to oneself, it is necessary to take advantage of opportunities.” This means that individuals who understand the laws of wealth, work diligently, and make the most of the chances that come their way are more likely to achieve their desires and avoid the misfortunes that befall those who falter or hesitate. \n",
            "\n",
            "In essence, Arkad taught that financial success is intertwined with being proactive and prepared, and that those who do not act on opportunities may miss out on the \"good luck\" they seek.\n",
            "Question: What does financial success mean in the context of the book?\n",
            "Answer: In \"The Richest Man in Babylon,\" Arkad believes that good luck follows opportunity because he understands that success and wealth are not merely the result of chance, but rather stem from preparation, awareness, and the ability to act upon the opportunities that life presents. Arkad highlights the significance of personal effort and desire as crucial elements in the journey toward financial success.\n",
            "\n",
            "He explains that those who take the initiative, prepare themselves, and possess a determined mindset are better equipped to recognize and seize chances when they arise. This perspective aligns with the overarching theme of the book, which emphasizes the importance of financial understanding and prudent management of resources. By applying the financial principles taught throughout the book, individuals can create their own opportunities for wealth and prosperity.\n",
            "\n",
            "Thus, Arkad's belief is grounded in the idea that what people often perceive as luck is actually the result of their preparedness to act on those opportunities, demonstrating that fortune favors the proactive and those willing to work for their goals. In this way, good luck is effectively a byproduct of opportunity recognized and acted upon.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reconstruction message\n",
        "reconstructing = f\"\"\"\n",
        "    Here are the questions and their answers:\n",
        "    {question_answer}\n",
        "    Now with answers to those questions and the original question: {question}, improve the original answer without changing the format of the answer.\n",
        "\n",
        "    Notes:\n",
        "    It's critical to just output the final answer.\n",
        "    It's critical to not output the annotated answer.\n",
        "    It's critical to not output constructed questions answer.\n",
        "\n",
        "    Final Answer:\n",
        "    \"\"\"\n",
        "reconstructing_message = message + [{\"role\": \"user\", \"content\": reconstructing}]"
      ],
      "metadata": {
        "id": "nYD10xzAyD-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_answer = client.chat.completions.create(\n",
        "    model='gpt-4o-mini',\n",
        "    messages=reconstructing_message,\n",
        ")"
      ],
      "metadata": {
        "id": "yE9Le1C5yQxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reconstructed_answer.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmmQ0HfGyUgS",
        "outputId": "f6c58be3-cda7-443c-e275-34447fcf8cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In \"The Richest Man in Babylon,\" Arkad, who is the richest man in Babylon, believes that good luck follows opportunity because he understands that wealth is not simply a matter of fate or luck; it is a result of taking action when opportunities present themselves. Throughout his life, he observed that many people fail to recognize the opportunities available to them or choose not to act on them. Instead of waiting for fortune to smile upon them, Arkad emphasized the importance of being proactive, diligent, and prepared to seize chances when they arise.\n",
            "\n",
            "According to Arkad, those who actively seek opportunities, educate themselves about how to manage and grow their wealth, and are willing to work and invest wisely are more likely to create their own \"luck.\" He noted that while opportunities are available to everyone, only a few grasp them and achieve their desires, while the majority hesitate or falter and consequently fall behind. This perspective underscores that luck is not merely random chance; rather, it is created through effort, willingness to take risks, and the ability to recognize and act on possibilities that life presents.\n",
            "\n",
            "In essence, Arkad's philosophy encourages readers to be proactive and to seek out opportunities, rather than relying solely on chance for financial success. He conveys that good luck is closely linked to the willingness to engage with life's opportunities, reinforcing the idea that preparation and action can transform luck from a mere chance event into a consistent part of one's journey towards success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLARE Function"
      ],
      "metadata": {
        "id": "I3J7pcgb1jTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flare(question, retriever, openai_api_key, openai_model='gpt-4o-mini', tolerance=-0.4, verbose=True):\n",
        "    '''\n",
        "    Uses a advanced RAG technique called FLARE to answer the question. It's an implementation\n",
        "    of the paper: \"Active Retrieval Augmented Generation\" Jiang ZB and fellow scientists in October\n",
        "    2023.\n",
        "\n",
        "    Args:\n",
        "      question: The question to be answered.\n",
        "      retriever: langchain retriever to be used.\n",
        "      openai_api_key: The OPENAI API key to be used.\n",
        "      openai_model: OpenAI Model to use\n",
        "      tolerance: The tolerance of logprobs to be marked as uncertain\n",
        "    Returns:\n",
        "      A 3-item tuple, which are all OpenAI objects. The items are the original answer,\n",
        "      annotated answer, and finally the improved answer.\n",
        "\n",
        "    '''\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    # getting the first output, normal rag\n",
        "    # get context\n",
        "    context = retriever.get_relevant_documents(question)\n",
        "\n",
        "    # constructing message\n",
        "    message = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a book expert that answers questions about books. Use the following pieces of retrieved context to answer the question.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "        Context: {format_docs(context)}\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"}\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Acquiring answer with traditional RAG...')\n",
        "    # answer the question\n",
        "    answer = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "        logprobs=True,\n",
        "    )\n",
        "\n",
        "    if verbose: print(f'Finding uncertain tokens, and annotating the answer...')\n",
        "    # annotate the question\n",
        "    annotated_answer = uncertain_marker(annotated_combiner(annotater(sequential_combine(\n",
        "        combine_token_to_word(answer), 5, np.mean), tolerance=tolerance), np.mean))\n",
        "\n",
        "    # constructing the questions for the uncertained answers\n",
        "    message += [\n",
        "        {\"role\": \"assistant\", \"content\": answer.choices[0].message.content},\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"Now, I have marked the answer to where you are uncertain with the phrases. For every, phrases in between\n",
        "        [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)].\n",
        "\n",
        "        This question is going to be used independently to get get relevant texts from a vector database\n",
        "        It's critical that the question includes the object and subject of the phrase\n",
        "        It's critical that the question has context about the annswer\n",
        "\n",
        "\n",
        "        First example:\n",
        "        user: What is meaning of the colors in the flag of Ghana?\n",
        "        assistant: Red is for the blood of martyrs, green for forests, and gold for mineral wealth.\n",
        "        user: Here's the annotated version: ([uncertain] Red [/uncertain]) is for the blood of martyrs, ([uncertain] green for forests [/uncertain]), and gold for mineral wealth.\n",
        "        assistant: [Search(is red a color in the flag of Ghana?)] is for the blood of martyrs, [Search(is green a color in the flag of Ghana? If so, what does it symbolize?)], and gold for mineral wealth.\n",
        "\n",
        "        Second example:\n",
        "        user: Give me a very short summary of Joe Biden's journey becoming the president!\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on August 18, 2019. His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        user: Here's an annotated version: Joe Biden announced his candidacy for the 2020 presidential election on ([uncertain] August 18, 2019 [/uncertain]). His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        assistant: Joe Biden announced his candidacy for the 2020 presidential election on [Search(When did Joe Biden announce his candidancy for the 2020 presidential election?)].  His campaign focused on issues such as restoring the 'soul of America', expanding healthcare access, and addressing climate change.\n",
        "        \"\"\"},\n",
        "        {\"role\": \"user\",\n",
        "            \"content\": f\"Here's the annotated version: {annotated_answer.choices[0].message.content}\"},\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Constructing questions for the annotated tokens...')\n",
        "    questions_construction = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "    )\n",
        "\n",
        "    # extracting the questions\n",
        "    message += [\n",
        "        {\"role\": \"assistant\",\n",
        "            \"content\": questions_construction.choices[0].message.content},\n",
        "        {'role': \"user\", \"content\": \"\"\"Now for all the questions marked as [Search(question)], please extract them in a python dictionary format:\n",
        "        {\n",
        "        \"1\": \"question 1\",\n",
        "        \"2\": \"question 2\",\n",
        "        ...\n",
        "        \"n\": \"question n\"\n",
        "        }\n",
        "\n",
        "        It is critical to only output the dictionary and nothing else.\n",
        "        It is critical to not output it in a markdown format.\n",
        "        It is critical that the first character of the output starts with an open curly bracket '{'\n",
        "      \"\"\"}\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Extracting constructed questions...')\n",
        "    questions = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=message,\n",
        "    )\n",
        "    retry_count= 1\n",
        "    try:\n",
        "        questions_dict = ast.literal_eval(questions.choices[0].message.content)\n",
        "    except:\n",
        "        while retry_count <= 3:\n",
        "            if verbose: print(f\"Couldn't convert to dictionary, attempting to fix the dictionary. Retry count: {retry_count}\")\n",
        "            questions = client.chat.completions.create(\n",
        "                model=openai_model,\n",
        "                messages=message,\n",
        "            )\n",
        "            try:\n",
        "                questions_dict = ast.literal_eval(questions.choices[0].message.content)\n",
        "                break\n",
        "            except:\n",
        "                retry_count += 1\n",
        "                continue\n",
        "        else:\n",
        "            print(f'FLARE Failed, try to call the function again.')\n",
        "            return\n",
        "\n",
        "    # message to answer the questions one by one\n",
        "    new_message = [\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"You are a book expert that answers questions about books.\n",
        "      Question: {question}\n",
        "      Context: called the RAG\n",
        "      Original Answer: {answer.choices[0].message.content}\n",
        "\n",
        "      Now, I have marked the answer to where you are uncertain with the phrases. For every, phrases in between\n",
        "      [uncertain] [/uncertain], please construct a question that will answer each uncertain phrase and mark it as [Search(question)]\n",
        "\n",
        "      Annotated Answer: {annotated_answer.choices[0].message.content}\n",
        "      Constructed Questions Answer: {questions_construction.choices[0].message.content}\n",
        "      \"\"\"},\n",
        "    ]\n",
        "\n",
        "    if verbose: print(f'Answering each questions...')\n",
        "    # answering each of the questions one by one\n",
        "    constructed_question_answer = {}\n",
        "    for i in range(1, len(questions_dict) + 1):\n",
        "        question_temp = questions_dict[str(i)]\n",
        "\n",
        "        # getting the context for the question\n",
        "        context = retriever.get_relevant_documents(question_temp)\n",
        "\n",
        "        # constructing the question and context message\n",
        "        question_string = f\"\"\"Use the following pieces of retrieved context to answer the question.\n",
        "        Question: {question}\n",
        "        Context: {format_docs(context)}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        question_message = new_message + \\\n",
        "            [{\"role\": \"user\", \"content\": question_string}]\n",
        "\n",
        "        # answering the question\n",
        "        question_answer = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=question_message,\n",
        "        )\n",
        "        constructed_question_answer[str(i)] = [\n",
        "            question_temp, question_answer.choices[0].message.content]\n",
        "\n",
        "    # reconstructing to get the final answer\n",
        "    question_answer = \"\"\n",
        "    for i in range(1, len(questions_dict) + 1):\n",
        "        question_answer += f\"\"\"Question: {questions_dict[str(i)]}\\nAnswer: {constructed_question_answer[str(i)][1]}\\n\"\"\"\n",
        "\n",
        "    reconstructing = f\"\"\"\n",
        "    Here are the questions and their answers:\n",
        "    {question_answer}\n",
        "    Now with answers to those questions and the original question: {question}, improve the original answer without changing the format of the answer.\n",
        "\n",
        "    Notes:\n",
        "    It's critical to just output the final answer.\n",
        "    It's critical to not output the annotated answer.\n",
        "    It's critical to not output constructed questions answer.\n",
        "\n",
        "    Final Answer:\n",
        "    \"\"\"\n",
        "    reconstructing_message = new_message + \\\n",
        "        [{\"role\": \"user\", \"content\": reconstructing}]\n",
        "    if verbose: print(f'Reconstructing the final answer...')\n",
        "    reconstructed_answer = client.chat.completions.create(\n",
        "        model=openai_model,\n",
        "        messages=reconstructing_message,\n",
        "    )\n",
        "\n",
        "    # printing some information\n",
        "    # It prints the question construction for the annotated answer because it's clearer to make the annotations as the questions itself\n",
        "    return answer, questions_construction, reconstructed_answer"
      ],
      "metadata": {
        "id": "p57cTyNG1rMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_questions.loc['the sixth cure', 1].hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC0BJqrk2JEd",
        "outputId": "f09fc3b4-fd88-4be6-df48-8b1ba1c630a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can a man ensure a future income according to the passage?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_answer_1, annotated_answer_1, final_answer_1 = flare(df_questions.loc['the sixth cure', 1].hard, retriever, userdata.get('OPENAI_API_KEY'), verbose=False)"
      ],
      "metadata": {
        "id": "SZIoH7vY1yu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_answer_1.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLlCOm4-2xb1",
        "outputId": "967c0544-a2fd-484f-f1e2-d6bcf388d841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the passage from \"The Sixth Cure,\" a man can ensure a future income by making careful preparations for his financial future, especially as he grows older. The key steps he can take include:\n",
            "\n",
            "1. **Preparation for Future Needs**: A man should make thoughtful preparations for a suitable income during his later years and for his family in case he is no longer able to support them.\n",
            "\n",
            "2. **Creating a Growing Surplus**: He should focus on acquiring a surplus of wealth that will allow him to invest in provisions or assets that will endure over time.\n",
            "\n",
            "3. **Investing Wisely**: The man is advised to carefully invest his treasure, avoiding risky ventures that promise high returns but may lead to significant losses. Instead, he should seek stable and secure investments.\n",
            "\n",
            "4. **Regular Contributions**: It’s recommended to make small, regular payments into protective plans or investments that can provide for future needs, ensuring family security in his absence.\n",
            "\n",
            "5. **Consulting Knowledgeable Advisors**: One should seek counsel from experts in finance to make informed decisions and avoid poor investments.\n",
            "\n",
            "Overall, the guidance emphasizes a proactive approach, careful planning, and the importance of safeguarding assets for future stability and the welfare of one’s family. Through prudent investments, regular savings, and thoughtful provisions, a man can create a secure financial future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All functions and datasets used have been placed in https://github.com/Justin-Jonany/FLARE_Implementation/tree/main"
      ],
      "metadata": {
        "id": "fKIiEDZW3YPj"
      }
    }
  ]
}